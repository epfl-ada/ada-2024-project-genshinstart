{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textgrad as tg\n",
    "import os\n",
    "import networkx as nx\n",
    "import csv\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from textgrad.tasks import load_task\n",
    "from textgrad.loss import MultiFieldTokenParsedEvaluation\n",
    "from textgrad import Variable\n",
    "import urllib\n",
    "from tqdm import tqdm\n",
    "from src.utils.data_utils import *\n",
    "from src.data.paths_loader import load_ai_paths, load_human_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = \"Your API Key\"\n",
    "\n",
    "llm_engine = tg.get_engine(\"gpt-4o-mini\")\n",
    "tg.set_backward_engine(tg.get_engine(\"gpt-4o\"), override=True)\n",
    "\n",
    "system_prompt = tg.Variable(\"\"\"You are an expert in navigating articles. Your goal is to find the path as short as possible from the start article to the target article by selecting the provided links. Each time you will be given (current article, destination) pair and the the next article that you could choose. \n",
    "                            \n",
    "                            Your output should include: \n",
    "                            \"Choice: \" followed by the title of the article you want to navigate to. \n",
    "                            \"Reason: \" followed by the reason why you chose that article.\n",
    "                            \"\"\",\n",
    "                            requires_grad=True,\n",
    "                            role_description=\"system prompt to guide the LLM's reasoning strategy for accurate responses\")\n",
    "\n",
    "model = tg.BlackboxLLM(llm_engine, system_prompt=system_prompt)\n",
    "\n",
    "df = pd.read_csv('wikispeedia_paths-and-graph/links.tsv', sep='\\t', comment='#', header=None, names=['origin', 'destination'])\n",
    "G = nx.from_pandas_edgelist(df, source='origin', target='destination', create_using=nx.DiGraph())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting the process...\n",
      "Average path length for Brain to Telephone: 5.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for Theatre to Zebra: 8.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for Pyramid to Bean: 5.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for Batman to Wood: 5.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for Bird to Great_white_shark: 9.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for Batman to The_Holocaust: 4.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "neighbors: ['18th_century', '19th_century', 'Anarchism', 'Anarcho-capitalism', 'Ancient_Greece', 'Aristotle', 'Augustus', 'Baruch_Spinoza', 'Bible', 'Capitalism', 'Civil_society', 'Communism', 'Confucius', 'Constitutional_monarchy', 'Corporation', 'David_Hume', 'Democracy', 'Edmund_Burke', 'Election', 'England', 'Ethics', 'Europe', 'Family', 'Force', 'France', 'French_Revolution', 'Government', 'Italy', 'Jean-Jacques_Rousseau', 'John_Locke', 'Karl_Marx', 'Karl_Popper', 'Liberal_democracy', 'Liberalism', 'Libertarianism', 'Marxism', 'Max_Weber', 'Monarchy', 'North_Korea', 'Oligarchy', 'Philosophy', 'Plato', 'Political_economy', 'Political_philosophy', 'Political_science', 'Religion', 'Renaissance', 'Roman_Empire', 'Society', 'Soviet_Union', 'Thomas_Hobbes', 'Thomas_Jefferson', 'United_States', 'Vladimir_Lenin', 'Voting', 'War']\n",
      "choice: Germany\n",
      "neighbors: ['18th_century', '19th_century', 'Anarchism', 'Anarcho-capitalism', 'Ancient_Greece', 'Aristotle', 'Augustus', 'Baruch_Spinoza', 'Bible', 'Capitalism', 'Civil_society', 'Communism', 'Confucius', 'Constitutional_monarchy', 'Corporation', 'David_Hume', 'Democracy', 'Edmund_Burke', 'Election', 'England', 'Ethics', 'Europe', 'Family', 'Force', 'France', 'French_Revolution', 'Government', 'Italy', 'Jean-Jacques_Rousseau', 'John_Locke', 'Karl_Marx', 'Karl_Popper', 'Liberal_democracy', 'Liberalism', 'Libertarianism', 'Marxism', 'Max_Weber', 'Monarchy', 'North_Korea', 'Oligarchy', 'Philosophy', 'Plato', 'Political_economy', 'Political_philosophy', 'Political_science', 'Religion', 'Renaissance', 'Roman_Empire', 'Society', 'Soviet_Union', 'Thomas_Hobbes', 'Thomas_Jefferson', 'United_States', 'Vladimir_Lenin', 'Voting', 'War']\n",
      "choice: Germany\n",
      "Average path length for Bird to Adolf_Hitler: No path found\n",
      "Invalid choices: 2, No path found: 0\n",
      "Average path length for Beer to Sun: 7.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for Batman to Banana: 6.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for Cat to Computer: 3.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for Cat to Microsoft: 5.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for Dog to Telephone: 5.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for Flower to Adolf_Hitler: 4.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for Automobile to Pluto: 5.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for Dog to Venus: 7.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for Batman to Bible: 5.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for Aluminium_chloride to Parrot: 6.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for England to God: 4.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for Achilles_tendon to Ocean: 5.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "neighbors: ['Aesthetics', 'Africa', 'Albert_Einstein', 'Animal_rights', 'Aristotle', 'Art', 'Astronomy', 'Atheism', 'Augustine_of_Hippo', 'Autocracy', 'Baghdad', 'Baruch_Spinoza', 'Bertrand_Russell', 'Biology', 'Blaise_Pascal', 'Buddha', 'Buddhism', 'China', 'Communism', 'Confucianism', 'Confucius', 'David_Hume', 'Democracy', 'Economics', 'Edmund_Burke', 'Empiricism', 'Ethics', 'Euclid', 'Francis_Bacon', 'Franz_Kafka', 'Friedrich_Nietzsche', 'Fyodor_Dostoevsky', 'Gautama_Buddha', 'Geometry', 'Gottfried_Leibniz', 'Immanuel_Kant', 'India', 'Industrial_Revolution', 'Iran', 'Iranian_peoples', 'Isaac_Newton', 'Islam', 'Jacques-Louis_David', 'Japan', 'Jean-Jacques_Rousseau', 'John_Locke', 'Karl_Marx', 'Karl_Popper', 'Laozi', 'Linguistics', 'Literature', 'Logic', 'Ludwig_Wittgenstein', 'Mahabharata', 'Mahatma_Gandhi', 'Marxism', 'Middle_East', 'Nature', 'Niccolò_Machiavelli', 'Noam_Chomsky', 'North_Africa', \"People's_Republic_of_China\", 'Philosophy_of_mind', 'Plato', 'Political_philosophy', 'Politics', 'Psychology', 'Ramayana', 'Religion', 'René_Descartes', 'Renaissance', 'Søren_Kierkegaard', 'Science', 'Senegal', 'Sigmund_Freud', 'Sociology', 'Socrates', 'Sun_Tzu', 'Tao_Te_Ching', 'Taoism', 'Thomas_Aquinas', 'Thomas_Hobbes', 'United_States', 'Utilitarianism', 'World_War_II', 'Zoroaster']\n",
      "choice: Music\n",
      "neighbors: ['Aesthetics', 'Africa', 'Albert_Einstein', 'Animal_rights', 'Aristotle', 'Art', 'Astronomy', 'Atheism', 'Augustine_of_Hippo', 'Autocracy', 'Baghdad', 'Baruch_Spinoza', 'Bertrand_Russell', 'Biology', 'Blaise_Pascal', 'Buddha', 'Buddhism', 'China', 'Communism', 'Confucianism', 'Confucius', 'David_Hume', 'Democracy', 'Economics', 'Edmund_Burke', 'Empiricism', 'Ethics', 'Euclid', 'Francis_Bacon', 'Franz_Kafka', 'Friedrich_Nietzsche', 'Fyodor_Dostoevsky', 'Gautama_Buddha', 'Geometry', 'Gottfried_Leibniz', 'Immanuel_Kant', 'India', 'Industrial_Revolution', 'Iran', 'Iranian_peoples', 'Isaac_Newton', 'Islam', 'Jacques-Louis_David', 'Japan', 'Jean-Jacques_Rousseau', 'John_Locke', 'Karl_Marx', 'Karl_Popper', 'Laozi', 'Linguistics', 'Literature', 'Logic', 'Ludwig_Wittgenstein', 'Mahabharata', 'Mahatma_Gandhi', 'Marxism', 'Middle_East', 'Nature', 'Niccolò_Machiavelli', 'Noam_Chomsky', 'North_Africa', \"People's_Republic_of_China\", 'Philosophy_of_mind', 'Plato', 'Political_philosophy', 'Politics', 'Psychology', 'Ramayana', 'Religion', 'René_Descartes', 'Renaissance', 'Søren_Kierkegaard', 'Science', 'Senegal', 'Sigmund_Freud', 'Sociology', 'Socrates', 'Sun_Tzu', 'Tao_Te_Ching', 'Taoism', 'Thomas_Aquinas', 'Thomas_Hobbes', 'United_States', 'Utilitarianism', 'World_War_II', 'Zoroaster']\n",
      "choice: Music\n",
      "Average path length for Calculus to Paul_McCartney: No path found\n",
      "Invalid choices: 2, No path found: 0\n",
      "Average path length for Aircraft to Google: 5.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for Electricity to God: 5.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for Art to Mango: 6.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for Brazil to Hydrogen: 5.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for Africa to England: 3.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for Archbishop_of_Canterbury to Vietnam: 4.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for Computer to Russia: 4.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for Computer to Fruit: 6.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for 14th_century to Rainbow: 5.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for Cat to Adolf_Hitler: 5.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for Jesus to God: 2.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for Manchester to Water: 3.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for China to Moon: 5.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for Antlion to Hip_hop_music: 5.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for Batman to Japan: 3.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "neighbors: ['19th_century', 'Africa', 'Anatomy', 'Animal', 'Anthropology', 'Bacteria', 'Beetle', 'Binomial_nomenclature', 'Biodiversity', 'Biosphere', 'Botany', 'Carbon', 'Carbon_dioxide', 'Cell_(biology)', 'Charles_Darwin', 'Climate', 'Climate_change', 'Creation-evolution_controversy', 'DNA', 'Drosophila_melanogaster', 'Earth', 'Ecology', 'Eukaryote', 'Evolution', 'Extinction', 'Fern', 'Fossil', 'Fungus', 'Gazelle', 'Genetic_code', 'Genetics', 'Geology', 'Human', 'Latin', 'Life', 'Lion', 'Mathematics', 'Medicine', 'Microscope', 'Natural_selection', 'Organism', 'Paleontology', 'Plant', 'Plate_tectonics', 'Prion', 'Science', 'Scientific_classification', 'Statistics', 'Thermodynamics', 'Virus', 'William_Harvey', 'Yeast']\n",
      "choice: Vitamin_D\n",
      "neighbors: ['19th_century', 'Africa', 'Anatomy', 'Animal', 'Anthropology', 'Bacteria', 'Beetle', 'Binomial_nomenclature', 'Biodiversity', 'Biosphere', 'Botany', 'Carbon', 'Carbon_dioxide', 'Cell_(biology)', 'Charles_Darwin', 'Climate', 'Climate_change', 'Creation-evolution_controversy', 'DNA', 'Drosophila_melanogaster', 'Earth', 'Ecology', 'Eukaryote', 'Evolution', 'Extinction', 'Fern', 'Fossil', 'Fungus', 'Gazelle', 'Genetic_code', 'Genetics', 'Geology', 'Human', 'Latin', 'Life', 'Lion', 'Mathematics', 'Medicine', 'Microscope', 'Natural_selection', 'Organism', 'Paleontology', 'Plant', 'Plate_tectonics', 'Prion', 'Science', 'Scientific_classification', 'Statistics', 'Thermodynamics', 'Virus', 'William_Harvey', 'Yeast']\n",
      "choice: Vitamin_D\n",
      "Average path length for Batman to Vitamin_D: No path found\n",
      "Invalid choices: 2, No path found: 0\n",
      "Average path length for Batman to Penguin: 6.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for Jesus to Adolf_Hitler: 6.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for Achilles_tendon to Ivory: 15.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for Batman to Albert_Einstein: 4.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for Brothers_Grimm to Windows_Vista: 8.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for Calculus to Lemon: 6.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for California to Adolf_Hitler: 4.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for Computer_programming to Fresh_water: 7.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for Automobile to Windows_XP: 5.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for Cat to Dog: 2.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for Apple to Banana: 3.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for China to Afghanistan: 4.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for God to Adolf_Hitler: 5.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for Linux to Adolf_Hitler: 12.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for Moon to Mars: 2.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for Apple to Fruit: 2.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for Bamako to Sun: 5.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "neighbors: ['Agriculture', 'Allosaurus', 'Anatomy', 'Ape', 'Archaeopteryx', 'Armadillo', 'Arthropod', 'Baboon', 'Bacteria', 'Biodiversity', 'Bioinformatics', 'Biology', 'Bird', 'Birth_control', 'Cambrian_explosion', 'Cancer', 'Cell_(biology)', 'Charles_Darwin', 'Chimpanzee', 'Computer', 'Creation-evolution_controversy', 'Creationism', 'Cretaceous-Tertiary_extinction_event', 'Crystal', 'DNA', 'Dinosaur', 'Ecology', 'Empiricism', 'Entropy', 'Eukaryote', 'Extinction', 'Fish', 'Fossil', 'Fossil_record', 'Francis_Crick', 'Galápagos_Islands', 'Genetic_code', 'Genetics', 'Geology', 'Glacier_National_Park_(US)', 'Gorilla', 'Gravitation', 'Gregor_Mendel', 'History_of_Earth', 'Ice_age', 'James_D._Watson', 'Judaism', 'Life', 'Malaria', 'Mineral', 'Mitochondrion', 'Natural_selection', 'Organism', 'Paleontology', 'Pea', 'Photosynthesis', 'Plant', 'Precambrian', 'Prion', 'Protein', 'Punctuated_equilibrium', 'Rain', 'Science', 'Sociology', 'South_America', 'Stephen_Jay_Gould', 'The_Origin_of_Species', 'Tiktaalik', 'United_States', 'Vertebrate', 'Vestigial_structure']\n",
      "choice: Astronomy\n",
      "neighbors: ['Agriculture', 'Allosaurus', 'Anatomy', 'Ape', 'Archaeopteryx', 'Armadillo', 'Arthropod', 'Baboon', 'Bacteria', 'Biodiversity', 'Bioinformatics', 'Biology', 'Bird', 'Birth_control', 'Cambrian_explosion', 'Cancer', 'Cell_(biology)', 'Charles_Darwin', 'Chimpanzee', 'Computer', 'Creation-evolution_controversy', 'Creationism', 'Cretaceous-Tertiary_extinction_event', 'Crystal', 'DNA', 'Dinosaur', 'Ecology', 'Empiricism', 'Entropy', 'Eukaryote', 'Extinction', 'Fish', 'Fossil', 'Fossil_record', 'Francis_Crick', 'Galápagos_Islands', 'Genetic_code', 'Genetics', 'Geology', 'Glacier_National_Park_(US)', 'Gorilla', 'Gravitation', 'Gregor_Mendel', 'History_of_Earth', 'Ice_age', 'James_D._Watson', 'Judaism', 'Life', 'Malaria', 'Mineral', 'Mitochondrion', 'Natural_selection', 'Organism', 'Paleontology', 'Pea', 'Photosynthesis', 'Plant', 'Precambrian', 'Prion', 'Protein', 'Punctuated_equilibrium', 'Rain', 'Science', 'Sociology', 'South_America', 'Stephen_Jay_Gould', 'The_Origin_of_Species', 'Tiktaalik', 'United_States', 'Vertebrate', 'Vestigial_structure']\n",
      "choice: Astronomy\n",
      "Average path length for Bird_migration to Hubble_Space_Telescope: No path found\n",
      "Invalid choices: 2, No path found: 0\n",
      "Average path length for Jew to Telephone: 4.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for Video to China: 4.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for Famine to Arctic: 6.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for AIDS to Jesus: 6.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for George_W._Bush to Monkey: 11.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for Human to Pluto: 4.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for Smog to Toy_Story: 10.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "neighbors: ['Animal', 'Antarctica', 'Asia', 'Biodiversity', 'Continent', 'Geography', 'Great_Salt_Lake', 'Himalayas', 'Ice_age', 'Ice_sheet', 'India', 'Irrigation', 'Landscape', 'Pea', 'Rain', 'Salt', 'Sand', 'Snow', 'Sunflower', 'United_States', 'Vegetation', 'Water', 'Yellow_River']\n",
      "choice: Sun\n",
      "neighbors: ['Animal', 'Antarctica', 'Asia', 'Biodiversity', 'Continent', 'Geography', 'Great_Salt_Lake', 'Himalayas', 'Ice_age', 'Ice_sheet', 'India', 'Irrigation', 'Landscape', 'Pea', 'Rain', 'Salt', 'Sand', 'Snow', 'Sunflower', 'United_States', 'Vegetation', 'Water', 'Yellow_River']\n",
      "choice: Sun\n",
      "Average path length for Pikachu to Sun: No path found\n",
      "Invalid choices: 2, No path found: 0\n",
      "Average path length for Earth to Odysseus: 4.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for 15th_century to Windows_Vista: 6.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for Batman to Peanut: 9.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for Bird to Thomas_Jefferson: 4.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for Chemistry to Fidel_Castro: 4.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for Dinosaur to China: 2.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "neighbors: ['16th_century', '17th_century', '18th_century', '19th_century', '20th_century', 'Ancient_Greece', 'Anthropology', 'Art', 'Astronomy', 'Berlin', 'Biosphere', 'Botany', 'Capitalism', 'Christopher_Columbus', 'Climate', 'Communication', 'Computer_science', 'Earth', \"Earth's_atmosphere\", 'Earthquake', 'Economics', 'Europe', 'Geology', 'Glaciology', 'Human', 'Hydrology', 'Immanuel_Kant', 'James_Cook', 'Logistics', 'Marco_Polo', 'Mathematics', 'Middle_Ages', 'Oceanography', 'Paris', 'Petroleum', 'Ptolemy', 'Pythagoras', 'Roman_Empire', 'Royal_Geographical_Society', 'Science', 'Sociology', 'Soil', 'Solar_System', 'Transport', 'University', 'Vegetation', 'Water']\n",
      "choice: Asia\n",
      "neighbors: ['16th_century', '17th_century', '18th_century', '19th_century', '20th_century', 'Ancient_Greece', 'Anthropology', 'Art', 'Astronomy', 'Berlin', 'Biosphere', 'Botany', 'Capitalism', 'Christopher_Columbus', 'Climate', 'Communication', 'Computer_science', 'Earth', \"Earth's_atmosphere\", 'Earthquake', 'Economics', 'Europe', 'Geology', 'Glaciology', 'Human', 'Hydrology', 'Immanuel_Kant', 'James_Cook', 'Logistics', 'Marco_Polo', 'Mathematics', 'Middle_Ages', 'Oceanography', 'Paris', 'Petroleum', 'Ptolemy', 'Pythagoras', 'Roman_Empire', 'Royal_Geographical_Society', 'Science', 'Sociology', 'Soil', 'Solar_System', 'Transport', 'University', 'Vegetation', 'Water']\n",
      "choice: Asia\n",
      "Average path length for John_Dee to China: No path found\n",
      "Invalid choices: 2, No path found: 0\n",
      "Average path length for Reptile to Jesus: 5.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for United_States to English_language: 4.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for Adolf_Hitler to Jesus: 4.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for Mario to Nintendo: 2.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for Pikachu to Jesus: 5.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "neighbors: ['Abidjan', 'Abuja', 'Accra', 'Addis_Ababa', 'African_Great_Lakes', 'African_Union', 'Afrikaans', 'Agriculture', 'Algeria', 'Algiers', 'Ancient_Egypt', 'Ancient_Greece', 'Ancient_Rome', 'Anglican_Communion', 'Angola', 'Antananarivo', 'Anthropology', 'Arabic_language', 'Asia', 'Atlantic_Ocean', 'Atlantic_slave_trade', 'Bamako', 'Banjul', 'Bantu', 'Belgium', 'Benin', 'Bissau', 'Botswana', 'Burkina_Faso', 'Burundi', \"Côte_d'Ivoire\", 'Cairo', 'Camel', 'Cameroon', 'Cape_Town', 'Cape_Verde', 'Capital', 'Carnivore', 'Central_African_Republic', 'Chad', 'Cheetah', 'China', 'Christianity', 'Civilization', 'Cocoa', 'Coffee', 'Cold_War', 'Comoros', 'Conakry', 'Congo_River', 'Continent', 'Cotton', 'Crocodile', 'Culture', 'Dakar', 'David_Livingstone', 'Deity', 'Democracy', 'Democratic_Republic_of_the_Congo', 'Desert', 'Despotism', 'Diamond', 'Djibouti', 'Earth', 'East_Africa', 'Egypt', 'El_Aaiún', 'Elephant', 'English_language', 'Equatorial_Guinea', 'Eritrea', 'Ethiopia', 'Europe', 'Famine', 'Flute', 'Fossil', 'France', 'Freetown', 'French_language', 'Funchal', 'Gabon', 'Gaborone', 'Ghana', 'Giraffe', 'Glacier', 'Gold', 'Great_Pyramid_of_Giza', 'Guinea', 'Guinea-Bissau', 'HIV', 'Harare', 'Henry_Morton_Stanley', 'Herbivore', 'Horn_of_Africa', 'Human', 'Hutu', 'Hyena', 'India', 'Indian_Ocean', 'Irrigation', 'Ishango_bone', 'Islam', 'Jazz', 'Judaism', 'Kenya', 'Khartoum', 'Kigali', 'Lake_Tanganyika', 'Lake_Victoria', 'Language', 'Las_Palmas_de_Gran_Canaria', 'Latin', 'Latin_America', 'Lesotho', 'Liberal_democracy', 'Liberia', 'Libreville', 'Libya', 'Lilongwe', 'Lion', 'Lomé', 'Lusaka', 'Madagascar', 'Malawi', 'Mali', 'Maputo', 'Maseru', 'Mauritania', 'Mauritius', 'Mayotte', 'Mbabane', 'Mediterranean_Sea', 'Middle_Ages', 'Military_dictatorship', 'Mitochondrial_Eve', 'Mogadishu', 'Monrovia', 'Morocco', 'Mozambique', 'Nairobi', 'Namibia', 'Netherlands', 'Niger', 'Nigeria', 'Nile', 'North_Africa', 'Nouakchott', 'Ouagadougou', 'Palm_oil', 'Persian_Empire', 'Pope', 'Port_Louis', 'Porto-Novo', 'Portugal', 'Portuguese_language', 'Poverty', 'Praia', 'Pretoria', 'Ptolemy', 'Réunion', 'Rabat', 'Rainforest', 'Red_Sea', 'Reggae', 'Republic_of_the_Congo', 'Rice', 'Richard_Francis_Burton', 'Royal_Navy', 'Rwanda', 'São_Tomé', 'São_Tomé_and_Príncipe', 'Saint_Helena', 'Scramble_for_Africa', 'Second_Congo_War', 'Senegal', 'Seychelles', 'Sierra_Leone', 'Somalia', 'Sorghum', 'Soukous', 'South_Africa', 'Southern_Africa', 'Soviet_Union', 'Spain', 'Sub-Saharan_Africa', 'Sudan', 'Suez_Canal', 'Swaziland', 'Tanzania', 'Temperate', 'The_Gambia', 'Timbuktu', 'Togo', 'Tripoli', 'Trumpet', 'Tunis', 'Tunisia', 'Tutsi', 'Uganda', 'United_Kingdom', 'United_Nations', 'United_States', 'United_States_Senate', 'Victoria,_Seychelles', 'Western_Sahara', 'World_War_I', 'World_War_II', 'Yamoussoukro', 'Zambia', 'Zheng_He', 'Zimbabwe', 'Zulu']\n",
      "choice: Mathematics\n",
      "neighbors: ['Abidjan', 'Abuja', 'Accra', 'Addis_Ababa', 'African_Great_Lakes', 'African_Union', 'Afrikaans', 'Agriculture', 'Algeria', 'Algiers', 'Ancient_Egypt', 'Ancient_Greece', 'Ancient_Rome', 'Anglican_Communion', 'Angola', 'Antananarivo', 'Anthropology', 'Arabic_language', 'Asia', 'Atlantic_Ocean', 'Atlantic_slave_trade', 'Bamako', 'Banjul', 'Bantu', 'Belgium', 'Benin', 'Bissau', 'Botswana', 'Burkina_Faso', 'Burundi', \"Côte_d'Ivoire\", 'Cairo', 'Camel', 'Cameroon', 'Cape_Town', 'Cape_Verde', 'Capital', 'Carnivore', 'Central_African_Republic', 'Chad', 'Cheetah', 'China', 'Christianity', 'Civilization', 'Cocoa', 'Coffee', 'Cold_War', 'Comoros', 'Conakry', 'Congo_River', 'Continent', 'Cotton', 'Crocodile', 'Culture', 'Dakar', 'David_Livingstone', 'Deity', 'Democracy', 'Democratic_Republic_of_the_Congo', 'Desert', 'Despotism', 'Diamond', 'Djibouti', 'Earth', 'East_Africa', 'Egypt', 'El_Aaiún', 'Elephant', 'English_language', 'Equatorial_Guinea', 'Eritrea', 'Ethiopia', 'Europe', 'Famine', 'Flute', 'Fossil', 'France', 'Freetown', 'French_language', 'Funchal', 'Gabon', 'Gaborone', 'Ghana', 'Giraffe', 'Glacier', 'Gold', 'Great_Pyramid_of_Giza', 'Guinea', 'Guinea-Bissau', 'HIV', 'Harare', 'Henry_Morton_Stanley', 'Herbivore', 'Horn_of_Africa', 'Human', 'Hutu', 'Hyena', 'India', 'Indian_Ocean', 'Irrigation', 'Ishango_bone', 'Islam', 'Jazz', 'Judaism', 'Kenya', 'Khartoum', 'Kigali', 'Lake_Tanganyika', 'Lake_Victoria', 'Language', 'Las_Palmas_de_Gran_Canaria', 'Latin', 'Latin_America', 'Lesotho', 'Liberal_democracy', 'Liberia', 'Libreville', 'Libya', 'Lilongwe', 'Lion', 'Lomé', 'Lusaka', 'Madagascar', 'Malawi', 'Mali', 'Maputo', 'Maseru', 'Mauritania', 'Mauritius', 'Mayotte', 'Mbabane', 'Mediterranean_Sea', 'Middle_Ages', 'Military_dictatorship', 'Mitochondrial_Eve', 'Mogadishu', 'Monrovia', 'Morocco', 'Mozambique', 'Nairobi', 'Namibia', 'Netherlands', 'Niger', 'Nigeria', 'Nile', 'North_Africa', 'Nouakchott', 'Ouagadougou', 'Palm_oil', 'Persian_Empire', 'Pope', 'Port_Louis', 'Porto-Novo', 'Portugal', 'Portuguese_language', 'Poverty', 'Praia', 'Pretoria', 'Ptolemy', 'Réunion', 'Rabat', 'Rainforest', 'Red_Sea', 'Reggae', 'Republic_of_the_Congo', 'Rice', 'Richard_Francis_Burton', 'Royal_Navy', 'Rwanda', 'São_Tomé', 'São_Tomé_and_Príncipe', 'Saint_Helena', 'Scramble_for_Africa', 'Second_Congo_War', 'Senegal', 'Seychelles', 'Sierra_Leone', 'Somalia', 'Sorghum', 'Soukous', 'South_Africa', 'Southern_Africa', 'Soviet_Union', 'Spain', 'Sub-Saharan_Africa', 'Sudan', 'Suez_Canal', 'Swaziland', 'Tanzania', 'Temperate', 'The_Gambia', 'Timbuktu', 'Togo', 'Tripoli', 'Trumpet', 'Tunis', 'Tunisia', 'Tutsi', 'Uganda', 'United_Kingdom', 'United_Nations', 'United_States', 'United_States_Senate', 'Victoria,_Seychelles', 'Western_Sahara', 'World_War_I', 'World_War_II', 'Yamoussoukro', 'Zambia', 'Zheng_He', 'Zimbabwe', 'Zulu']\n",
      "choice: Mathematics\n",
      "Average path length for Africa to Differential_equation: No path found\n",
      "Invalid choices: 2, No path found: 0\n",
      "Average path length for Cat to University: 5.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for Citrus to Physics: 4.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for Computer to Whale: 7.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for Dinosaur to George_W._Bush: 4.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for England to Train: 4.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for North_America to Canada: 2.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for The_Godfather to Neptune: 17.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for Volcano to Alphabet: 4.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for Nintendo to Snow: 8.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for Bangladesh to Harry_S._Truman: 4.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for Computer to Baseball: 4.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for Electricity to Anne_Frank: 9.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for Achilles to Winston_Churchill: 4.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for Aircraft to Yugoslavia: 5.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for AT%26T to Vegetable: 4.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for Batman to Jesus: 5.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for Beer to Warsaw: 4.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for Colombia to Meat: 4.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for Dog to Sea: 4.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for England to Japan: 3.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for Linguistics to Rome: 4.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for Metal to Prague: 13.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for Jesus to Google: 7.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for History to Nazi_Germany: 4.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for Fourteenth_Amendment_to_the_United_States_Constitution to Reptile: 7.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for Arnold_Schwarzenegger to Vegetable: 6.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for Google to God: 5.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "neighbors: ['Acts_of_Union_1707', 'Adam_Smith', 'Airbus', 'Anglican_Communion', 'Anne_of_Great_Britain', 'Archbishop_of_Canterbury', 'Arctic_Monkeys', 'Argentina', 'Arsenal_F.C.', 'Atlantic_Ocean', 'BAE_Systems', 'Bangladesh', 'Belfast', 'Ben_Jonson', 'Ben_Nevis', 'Benjamin_Britten', 'Bermuda', 'Bertrand_Russell', 'Bicycle', 'British_Empire', 'British_House_of_Commons', 'British_Isles', 'British_monarchy', 'Buckingham_Palace', 'Canada', 'Canterbury_Cathedral', 'Capitalism', 'Cardiff', 'Celtic_F.C.', 'Channel_Islands', 'Charles_Darwin', 'Charles_Dickens', 'Charles_II_of_England', 'Chelsea_F.C.', 'Christianity', 'Christopher_Wren', 'Church_of_England', 'Church_of_Ireland', 'City_status_in_the_United_Kingdom', 'Computer', 'Constitutional_monarchy', 'Cotswolds', 'Cricket', 'Currency', 'DNA', 'Damon_Hill', 'Earth', 'Edinburgh', 'Electron', 'Elizabeth_II_of_the_United_Kingdom', 'England', 'English_Channel', 'English_language', 'Euro', 'Europe', 'European_Union', 'Football_(soccer)', 'Formula_One', 'France', 'Francis_Crick', 'French_language', 'Germany', \"Giant's_Causeway\", 'Gibraltar', 'Glasgow', 'GlaxoSmithKline', 'Gordon_Brown', 'Grand_Slam_(tennis)', 'Gravitation', 'Great_Britain', 'Guernsey', 'HSBC', 'Hebrides', 'Henry_Purcell', 'Henry_VIII_of_England', 'Hindi', 'Hinduism', 'House_of_Lords', 'Hydrogen', 'India', 'Industrial_Revolution', 'Ireland', 'Irish_Sea', 'Iron_Maiden', 'Isambard_Kingdom_Brunel', 'Islam', 'Isle_of_Man', 'Italy', 'J._K._Rowling', 'J._M._W._Turner', 'J._R._R._Tolkien', 'James_Clerk_Maxwell', 'Jane_Austen', 'Jersey', 'Jet_engine', 'John_Milton', 'Judaism', 'Kylie_Minogue', 'Lake_District', 'Latin', 'Laws_in_Wales_Acts_1535–1542', 'Lion', 'List_of_countries_by_system_of_government', 'Liverpool_F.C.', 'Local_government_in_the_United_Kingdom', 'Loch', 'London', 'Manchester_United_F.C.', 'Market', 'Michael_Faraday', 'Monarchy', 'Montserrat', 'NATO', 'Natural_gas', 'North_Sea', 'Northern_Ireland', 'Novel', 'Oasis_(band)', 'Olympic_Games', 'Opera', 'Orkney', 'Pakistan', 'Palace_of_Westminster', 'Parliament_of_the_United_Kingdom', 'Parliamentary_system', 'Peak_District', 'Petroleum', 'Plymouth', 'Pound_sterling', 'Prime_Minister_of_the_United_Kingdom', 'Principality', 'Queen_(band)', 'Republic_of_Ireland', 'River_Thames', 'Roman_Britain', 'Royal_Air_Force', 'Royal_Marines', 'Royal_Navy', 'Rugby_World_Cup', 'Rugby_football', 'Saint_Helena', 'Scotland', 'Scots_language', 'Scottish_Gaelic_language', 'Scottish_Highlands', 'Sikhism', 'Somalia', 'Spain', 'Sport', 'Steel', 'T._S._Eliot', 'Television', 'Tennis', 'The_Beatles', 'The_Championships,_Wimbledon', 'The_Rolling_Stones', 'Time_zone', 'Tony_Blair', 'Trafalgar_Square', 'United_Nations', 'United_States_dollar', 'University_of_Cambridge', 'Wales', 'Westminster_Abbey', 'William_Shakespeare', 'World_Heritage_Site', 'World_War_I', 'World_War_II']\n",
      "choice: Australia\n",
      "neighbors: ['Acts_of_Union_1707', 'Adam_Smith', 'Airbus', 'Anglican_Communion', 'Anne_of_Great_Britain', 'Archbishop_of_Canterbury', 'Arctic_Monkeys', 'Argentina', 'Arsenal_F.C.', 'Atlantic_Ocean', 'BAE_Systems', 'Bangladesh', 'Belfast', 'Ben_Jonson', 'Ben_Nevis', 'Benjamin_Britten', 'Bermuda', 'Bertrand_Russell', 'Bicycle', 'British_Empire', 'British_House_of_Commons', 'British_Isles', 'British_monarchy', 'Buckingham_Palace', 'Canada', 'Canterbury_Cathedral', 'Capitalism', 'Cardiff', 'Celtic_F.C.', 'Channel_Islands', 'Charles_Darwin', 'Charles_Dickens', 'Charles_II_of_England', 'Chelsea_F.C.', 'Christianity', 'Christopher_Wren', 'Church_of_England', 'Church_of_Ireland', 'City_status_in_the_United_Kingdom', 'Computer', 'Constitutional_monarchy', 'Cotswolds', 'Cricket', 'Currency', 'DNA', 'Damon_Hill', 'Earth', 'Edinburgh', 'Electron', 'Elizabeth_II_of_the_United_Kingdom', 'England', 'English_Channel', 'English_language', 'Euro', 'Europe', 'European_Union', 'Football_(soccer)', 'Formula_One', 'France', 'Francis_Crick', 'French_language', 'Germany', \"Giant's_Causeway\", 'Gibraltar', 'Glasgow', 'GlaxoSmithKline', 'Gordon_Brown', 'Grand_Slam_(tennis)', 'Gravitation', 'Great_Britain', 'Guernsey', 'HSBC', 'Hebrides', 'Henry_Purcell', 'Henry_VIII_of_England', 'Hindi', 'Hinduism', 'House_of_Lords', 'Hydrogen', 'India', 'Industrial_Revolution', 'Ireland', 'Irish_Sea', 'Iron_Maiden', 'Isambard_Kingdom_Brunel', 'Islam', 'Isle_of_Man', 'Italy', 'J._K._Rowling', 'J._M._W._Turner', 'J._R._R._Tolkien', 'James_Clerk_Maxwell', 'Jane_Austen', 'Jersey', 'Jet_engine', 'John_Milton', 'Judaism', 'Kylie_Minogue', 'Lake_District', 'Latin', 'Laws_in_Wales_Acts_1535–1542', 'Lion', 'List_of_countries_by_system_of_government', 'Liverpool_F.C.', 'Local_government_in_the_United_Kingdom', 'Loch', 'London', 'Manchester_United_F.C.', 'Market', 'Michael_Faraday', 'Monarchy', 'Montserrat', 'NATO', 'Natural_gas', 'North_Sea', 'Northern_Ireland', 'Novel', 'Oasis_(band)', 'Olympic_Games', 'Opera', 'Orkney', 'Pakistan', 'Palace_of_Westminster', 'Parliament_of_the_United_Kingdom', 'Parliamentary_system', 'Peak_District', 'Petroleum', 'Plymouth', 'Pound_sterling', 'Prime_Minister_of_the_United_Kingdom', 'Principality', 'Queen_(band)', 'Republic_of_Ireland', 'River_Thames', 'Roman_Britain', 'Royal_Air_Force', 'Royal_Marines', 'Royal_Navy', 'Rugby_World_Cup', 'Rugby_football', 'Saint_Helena', 'Scotland', 'Scots_language', 'Scottish_Gaelic_language', 'Scottish_Highlands', 'Sikhism', 'Somalia', 'Spain', 'Sport', 'Steel', 'T._S._Eliot', 'Television', 'Tennis', 'The_Beatles', 'The_Championships,_Wimbledon', 'The_Rolling_Stones', 'Time_zone', 'Tony_Blair', 'Trafalgar_Square', 'United_Nations', 'United_States_dollar', 'University_of_Cambridge', 'Wales', 'Westminster_Abbey', 'William_Shakespeare', 'World_Heritage_Site', 'World_War_I', 'World_War_II']\n",
      "choice: Australia\n",
      "Average path length for Harry_Potter to Kangaroo: No path found\n",
      "Invalid choices: 2, No path found: 0\n",
      "Average path length for Acceleration to Mozilla_Firefox: 7.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "neighbors: ['Africa', 'Alcohol', 'Ammonia', 'Andes', 'Arable_land', 'Barley', 'Beekeeping', 'Biodiesel', 'Botany', 'Cereal', 'Cocoa', 'Coffee', 'Cotton', 'Egg_(food)', 'Egypt', 'Ethanol', 'Fertile_Crescent', 'Fertilizer', 'Fish', 'Flower', 'Food', 'Fossil_fuel', 'France', 'Fruit', 'Germany', 'Global_warming', 'History_of_the_world', 'Honey', 'Horse', 'Indonesia', 'Irrigation', 'Maize', 'Meat', 'Mesopotamia', 'Middle_Ages', 'Milk', 'Nitrogen', 'Nutrition', 'Pea', 'Phosphorus', 'Potato', 'Rice', 'River', 'Soil', 'Soil_salination', 'Sorghum', 'South_America', 'Soybean', 'Sugar', 'Sumer', 'Sweden', 'Tea', 'Tobacco', 'Vegetable', 'Virgil', 'Weed', 'Wheat']\n",
      "choice: Bird\n",
      "neighbors: ['Africa', 'Alcohol', 'Ammonia', 'Andes', 'Arable_land', 'Barley', 'Beekeeping', 'Biodiesel', 'Botany', 'Cereal', 'Cocoa', 'Coffee', 'Cotton', 'Egg_(food)', 'Egypt', 'Ethanol', 'Fertile_Crescent', 'Fertilizer', 'Fish', 'Flower', 'Food', 'Fossil_fuel', 'France', 'Fruit', 'Germany', 'Global_warming', 'History_of_the_world', 'Honey', 'Horse', 'Indonesia', 'Irrigation', 'Maize', 'Meat', 'Mesopotamia', 'Middle_Ages', 'Milk', 'Nitrogen', 'Nutrition', 'Pea', 'Phosphorus', 'Potato', 'Rice', 'River', 'Soil', 'Soil_salination', 'Sorghum', 'South_America', 'Soybean', 'Sugar', 'Sumer', 'Sweden', 'Tea', 'Tobacco', 'Vegetable', 'Virgil', 'Weed', 'Wheat']\n",
      "choice: Bird\n",
      "Average path length for Agriculture to Sparrow: No path found\n",
      "Invalid choices: 2, No path found: 0\n",
      "Average path length for Aircraft to Solar_eclipse: 6.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for Batman to Superman: 2.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for Batman to Bill_Clinton: 5.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for Batman to Coconut_crab: 9.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for Brazil to Vitamin: 4.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for Citrus to Desert: 5.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for Continent to Gorilla: 9.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for David_Beckham to Great_white_shark: 13.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for Dog to Elementary_algebra: 8.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for Flower to George_H._W._Bush: 5.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for Forth to Anne_Frank: 12.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for Mormon to Ice: 6.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for Solar_System to Babe_Ruth: 5.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for Ocean to Love: 8.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for Seed to New_York_City: 5.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for Weed to Jesus: 5.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for Scent_of_a_Woman to Firearm: 10.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for Meteorological_history_of_Hurricane_Katrina to Iraq_War: 5.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for Chocolate to Velociraptor: 15.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for Mario to God: 5.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for Age_of_Enlightenment to Kazakhstan: 7.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for American_Civil_War to Kuwait_City: 5.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for Anaconda to Agnosticism: 5.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for Archbishop_of_Canterbury to Neil_Armstrong: 8.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for California to Middle_East: 3.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for Canada to Pony: 6.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for Chemistry to George_H._W._Bush: 5.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for Colombia to 6th_century: 5.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for Dodo to Film: 5.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for Dog to Beer: 4.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for Germany to Adolf_Hitler: 2.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for Global_warming to Wood: 4.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for God to Aztec: 6.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for Gregorian_chant to Inductance: 10.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for Hydrogen to Gold: 4.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for Judaism to Flute: 8.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for Mathematics to Juice: 15.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "neighbors: ['AIDS', 'African_slave_trade', 'Agriculture', 'Alexander_the_Great', 'Ancient_Egypt', 'Angola', 'Asia', 'Automobile', 'Belgium', 'Botswana', 'Burundi', 'Byzantine_Empire', 'Camel', 'Cape_Verde', 'Capital', 'China', 'Coal', 'Cocoa', 'Coffee', 'Cold_War', 'Communism', 'Comoros', 'Congo_River', 'Copper', 'Cotton', 'Democratic_Republic_of_the_Congo', 'Desert', 'Desert_locust', 'Despotism', 'Diamond', 'Drought', 'Education', 'Egypt', 'Electricity', 'Elephant', 'English_language', 'Equatorial_Guinea', 'Eritrea', 'Ethiopia', 'Europe', 'European_Union', 'Famine', 'Forest', 'French_language', 'Gabon', 'Gold', 'HIV', 'Horn_of_Africa', 'India', 'Indian_Ocean', 'Indonesia', 'Infrastructure', 'Internet', 'Ivory', 'Japan', 'Lagos', 'Libya', 'Literacy', 'Maghreb', 'Malaria', 'Marxism', 'Mauritius', 'Mediterranean_Sea', 'Middle_East', 'Military_dictatorship', 'Mineral', 'Mozambique', 'Niger_River', 'Nigeria', 'Nile', 'North_Africa', 'North_America', 'Palm_oil', 'Persian_Gulf', 'Petroleum', 'Portugal', 'Portuguese_language', 'Poverty', 'Radio', 'Rainforest', 'Roman_Empire', 'Rwanda', 'Sahara', 'Salt', 'Scramble_for_Africa', 'Second_Congo_War', 'Seychelles', 'Somalia', 'South_Africa', 'South_America', 'Soviet_Union', 'Steel', 'Sub-Saharan_Africa', 'Swaziland', 'Tanzania', 'Television', 'Tutsi', 'United_Nations', 'United_States', 'Zambezi']\n",
      "choice: Africa\n",
      "neighbors: ['AIDS', 'African_slave_trade', 'Agriculture', 'Alexander_the_Great', 'Ancient_Egypt', 'Angola', 'Asia', 'Automobile', 'Belgium', 'Botswana', 'Burundi', 'Byzantine_Empire', 'Camel', 'Cape_Verde', 'Capital', 'China', 'Coal', 'Cocoa', 'Coffee', 'Cold_War', 'Communism', 'Comoros', 'Congo_River', 'Copper', 'Cotton', 'Democratic_Republic_of_the_Congo', 'Desert', 'Desert_locust', 'Despotism', 'Diamond', 'Drought', 'Education', 'Egypt', 'Electricity', 'Elephant', 'English_language', 'Equatorial_Guinea', 'Eritrea', 'Ethiopia', 'Europe', 'European_Union', 'Famine', 'Forest', 'French_language', 'Gabon', 'Gold', 'HIV', 'Horn_of_Africa', 'India', 'Indian_Ocean', 'Indonesia', 'Infrastructure', 'Internet', 'Ivory', 'Japan', 'Lagos', 'Libya', 'Literacy', 'Maghreb', 'Malaria', 'Marxism', 'Mauritius', 'Mediterranean_Sea', 'Middle_East', 'Military_dictatorship', 'Mineral', 'Mozambique', 'Niger_River', 'Nigeria', 'Nile', 'North_Africa', 'North_America', 'Palm_oil', 'Persian_Gulf', 'Petroleum', 'Portugal', 'Portuguese_language', 'Poverty', 'Radio', 'Rainforest', 'Roman_Empire', 'Rwanda', 'Sahara', 'Salt', 'Scramble_for_Africa', 'Second_Congo_War', 'Seychelles', 'Somalia', 'South_Africa', 'South_America', 'Soviet_Union', 'Steel', 'Sub-Saharan_Africa', 'Swaziland', 'Tanzania', 'Television', 'Tutsi', 'United_Nations', 'United_States', 'Zambezi']\n",
      "choice: Africa\n",
      "Average path length for Shark to FIFA: No path found\n",
      "Invalid choices: 2, No path found: 0\n",
      "Average path length for Booby to Ununhexium: 8.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for Jesus to Microsoft: 8.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for Pluto to Wall_Street: 5.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for Brain to DVD: 5.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for Planet to Nuclear_power: 5.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for James_Bond to Human_rights: 3.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for Pyramid to Adolf_Hitler: 5.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for Tennis to Nuclear_weapon: 4.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for Khudai_Khidmatgar to Whale: 8.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for Earless_seal to Citrus: 6.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for Wasp to United_Arab_Emirates: 7.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for Weasel to Barium: 9.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for Alpaca to Nuclear_fission: 5.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for Australian_Open to George_W._Bush: 4.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for Necktie to Lion: 3.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "neighbors: ['18th_century', '19th_century', 'Bible', 'Book', 'Charles_Dickens', 'China', 'Corporation', 'Drama', 'Drawing', 'E._E._Cummings', 'Epic_of_Gilgamesh', 'Fiction', 'Film', 'Genealogy', 'History', 'Homer', 'India', 'Iran', 'Japan', 'John_Milton', 'Latin', 'Mahabharata', 'Middle_Ages', 'Miguel_de_Cervantes', 'Music', 'Mythology', 'Nationalism', 'Nature', 'Novel', 'Odyssey', 'Opera', 'Philosophy', 'Poetry', 'Psychology', 'Publishing', 'Ramayana', 'Religion', 'Romanticism', 'Sculpture', 'Spain', 'Theatre', 'William_Shakespeare', 'Writing']\n",
      "choice: Health\n",
      "neighbors: ['18th_century', '19th_century', 'Bible', 'Book', 'Charles_Dickens', 'China', 'Corporation', 'Drama', 'Drawing', 'E._E._Cummings', 'Epic_of_Gilgamesh', 'Fiction', 'Film', 'Genealogy', 'History', 'Homer', 'India', 'Iran', 'Japan', 'John_Milton', 'Latin', 'Mahabharata', 'Middle_Ages', 'Miguel_de_Cervantes', 'Music', 'Mythology', 'Nationalism', 'Nature', 'Novel', 'Odyssey', 'Opera', 'Philosophy', 'Poetry', 'Psychology', 'Publishing', 'Ramayana', 'Religion', 'Romanticism', 'Sculpture', 'Spain', 'Theatre', 'William_Shakespeare', 'Writing']\n",
      "choice: Health\n",
      "Average path length for Sonic_the_Hedgehog_%28character%29 to Cancer: No path found\n",
      "Invalid choices: 2, No path found: 0\n"
     ]
    }
   ],
   "source": [
    "# Try before tuning the prompt\n",
    "\n",
    "import builtins\n",
    "\n",
    "print(\"Starting the process...\")\n",
    "ori_dest = pd.read_csv('ori_dest.csv').iloc[:, 0].tolist()\n",
    "ori_dest = ori_dest\n",
    "ori_dest = [builtins.eval(pair) for pair in ori_dest]\n",
    "save_dir = 'paths_before_tuning'\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "for pair in ori_dest:\n",
    "    start_article, target_article = pair\n",
    "    paths = []\n",
    "    for _ in range(2):\n",
    "        path = generate_path(start_article, target_article, G, model)\n",
    "        paths.append(path)\n",
    "    with open(f'{save_dir}/{start_article}_{target_article}.csv', 'w') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows(paths)\n",
    "    # calculate the average path length\n",
    "    path_lengths = [len(path) for path in paths if path[-1] != 'No path found' and path[-1] != 'Invalid choice']\n",
    "    if len(path_lengths) == 0:\n",
    "        avg_path_length = 'No path found'\n",
    "    else:\n",
    "        avg_path_length = np.mean(path_lengths)\n",
    "    print(f'Average path length for {start_article} to {target_article}: {avg_path_length}')\n",
    "    print(f'Invalid choices: {len([path for path in paths if path[-1] == \"Invalid choice\"])}, No path found: {len([path for path in paths if path[-1] == \"No path found\"])}')\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "format_string = \"\"\"\n",
    "LLM Prompt: {system_prompt}\n",
    "Query: {query}\n",
    "Prediction: {pred}\n",
    "Ground Truth: {target} \n",
    "Evaluation: {eval}\n",
    "\"\"\"\n",
    "\n",
    "loss_system_prompt = tg.Variable(\"\"\"he LLM needs to find the article that requires possibly fewer steps to reach the destination in a graph where nodes correspond to articles and edges represent links between articles. Your task is to evaluate and provide concise feedback on the LLM's choice of the next article to navigate to.\n",
    "                                 The LLM only has access to the titles of current article and destination article, and the list of article titles to choose from (the links in current article), No any other information such as the previous choices, optimal path, correct solutions. \n",
    "                                 The LLM's output should include: \"Choice\" which is the article it wants to access, should be exactly in the provided list, and \"Reason\".\n",
    "                                 You will receive the <current, destination> pair, the LLM's prediction the list of optimal solutions (first steps in all possible shortest paths).\n",
    "                                 You need to provide concise feedback to correct the LLM's prediction.\n",
    "                                 \"\"\",\n",
    "                                 role_description=\"System prompt to provide feedback\", \n",
    "                                 requires_grad=False)\n",
    "\n",
    "fields = {\"system_prompt\": None, \"query\": None, \"pred\": None, \"target\": None, \"eval\": None}\n",
    "\n",
    "formatted_llm_call = tg.autograd.FormattedLLMCall(engine=tg.get_engine(\"gpt-4o\"), fields=fields, format_string=format_string, system_prompt=loss_system_prompt)\n",
    "optimizer = tg.TGD([system_prompt])\n",
    "\n",
    "def loss_fn(system_prompt, query, pred, target, eval):\n",
    "    return formatted_llm_call(inputs={\"system_prompt\": system_prompt, \"query\": query, \"pred\": pred, \"target\": target, \"eval\": eval})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/24 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renaissance\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1/24 [00:02<01:01,  2.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fish\n",
      "Choice: Fish  \n",
      "Reason: The article \"Fish\" is a broader category that includes sharks, and it is likely to have links to geographical locations or other related topics that could lead to \"Lusaka\".\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 2/24 [00:05<01:01,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Europe\n",
      "Choice: Europe  \n",
      "Reason: Europe is a broad category that can potentially connect to various topics, including elements and their classifications, which may lead to the target article \"List_of_elements_by_name\".\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 3/24 [00:09<01:08,  3.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "England\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 4/24 [00:12<01:00,  3.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "England\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 5/24 [00:15<00:57,  3.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mathematics\n",
      "Choice: Mathematics  \n",
      "Reason: \"Mathematics\" is a broader topic that may contain links to geographical concepts or areas, such as the \"Lake District,\" which is often discussed in relation to mathematical applications or historical significance in the context of geography. The other options seem less likely to connect to the target article.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 6/24 [02:07<12:07, 40.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Denmark\n",
      "Choice: \"Denmark\"  \n",
      "Reason: Søren Kierkegaard was a Danish philosopher, and his work is deeply rooted in the cultural and historical context of Denmark. By selecting \"Denmark,\" I can explore more about the geographical and cultural background that influenced Kierkegaard's philosophy, which may lead to broader connections that could eventually link to Howland Island, especially if there are historical ties or discussions about Danish exploration or territories.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 7/24 [02:12<08:04, 28.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "United_States_Congress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 8/24 [02:15<05:29, 20.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "British_Empire\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 9/24 [02:19<03:49, 15.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "British_House_of_Commons\n",
      "Choice: \"British_House_of_Commons\"  \n",
      "Reason: The British House of Commons is a central institution in the UK political system, and Harold Wilson served as Prime Minister, which connects him directly to this article. From the British House of Commons, there are likely to be links to broader themes of governance, philosophy, and political thought, which can lead to discussions about humanism, especially in the context of political ideologies and social policies. This choice provides a strong contextual bridge to the target article.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 10/24 [02:23<02:46, 11.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Light\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 11/24 [02:26<01:59,  9.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bird\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 12/24 [04:42<09:31, 47.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "England\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 13/24 [04:45<06:16, 34.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rail_transport\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 14/24 [04:57<04:35, 27.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History\n",
      "Choice: History  \n",
      "Reason: The article \"History\" serves as a broad thematic link that encompasses various periods, including both the Stone Age and the Age of Enlightenment. By selecting \"History,\" I can explore the connections between these two significant eras, which may lead to more specific articles related to the Age of Enlightenment in subsequent steps. This choice minimizes the distance to the target article by focusing on a central theme that is likely to contain relevant information.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▎   | 15/24 [05:10<03:27, 23.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "London\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 16/24 [05:13<02:16, 17.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plant\n",
      "Choice: \"Plant\"  \n",
      "Reason: The article \"Plant\" is directly related to the topic of \"Sesame,\" as sesame is a type of plant. Additionally, the article \"Plant\" may provide connections to various species, including those that could lead to the target article \"Crow,\" which is a bird. This choice is likely to open up pathways related to biological classification and ecological relationships, which could be relevant in finding a link to \"Crow.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 17/24 [05:23<01:44, 14.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gas_giant\n",
      "Choice: \"Gas_giant\"  \n",
      "Reason: The article \"Saturn\" is a gas giant, and selecting \"Gas_giant\" will provide a more focused context on the characteristics and classifications of planets like Saturn. This could potentially lead to articles that discuss broader astronomical concepts, which may include connections to scientific studies or theories that could relate to mental health topics, such as schizophrenia. While it may not seem directly related, understanding the classification of planets could lead to discussions about the universe and its impact on human psychology, which might eventually connect to the target article.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 18/24 [07:25<04:43, 47.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chemical_element\n",
      "Choice: \"Chemical_element\"  \n",
      "Reason: The article \"Chemical_element\" serves as a foundational concept in chemistry that encompasses all elements, including lanthanum and pi (as a mathematical constant). By navigating to \"Chemical_element,\" I can establish a broader context that may lead to further connections to mathematical concepts, including \"Pi.\" This choice is likely to provide a more direct pathway to the target article compared to the other options, which are primarily focused on specific elements or unrelated topics.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 19/24 [07:30<02:52, 34.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Roman_Catholic_Church\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 20/24 [07:34<01:41, 25.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "United_States_dollar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 21/24 [07:39<00:57, 19.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brazil\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 22/24 [07:43<00:29, 14.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Halloween\n",
      "Choice: Halloween  \n",
      "Reason: While the initial connection to \"Pony\" may not seem direct, \"Halloween\" is a culturally significant event that often features ponies in various forms, such as pony rides or themed decorations. This choice allows for a thematic exploration that could lead to connections with children's culture, festivities, and potentially to the concept of ponies in a broader context. Other options, such as tennis-related articles, do not provide a clear thematic link to \"Pony.\" Therefore, navigating to \"Halloween\" may open up more relevant pathways toward the target article.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 23/24 [07:48<00:11, 11.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alfred_the_Great\n",
      "Choice: \"Alfred_the_Great\"  \n",
      "Reason: Alfred the Great is a significant historical figure associated with the 9th century, which is directly relevant to the target article \"8th_century.\" By selecting this link, I can potentially explore connections to the historical context of the 8th century, particularly in relation to the development of the English language and culture during that time. This choice provides a more focused pathway towards understanding the historical backdrop of the 8th century, rather than diverging into broader or less relevant topics.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [10:03<00:00, 25.17s/it]\n"
     ]
    }
   ],
   "source": [
    "# Larger batch size will exceede token limit in gpt-4o\n",
    "batch_size = 6\n",
    "losses = []\n",
    "for _ in tqdm(range(24)):\n",
    "    question, answer, neighbors, optimal_choices = get_question_and_answer(G)\n",
    "    question = tg.Variable(question, role_description=\"Navigation query\", requires_grad=False)\n",
    "    answer = tg.Variable(answer, role_description=\"Optimal solutions\", requires_grad=False)\n",
    "\n",
    "    prediction = model(question)\n",
    "\n",
    "    choice = str(prediction).split(\":\")[1].split(\"\\n\")[0].strip()\n",
    "    if '\"' in choice:\n",
    "        choice = choice[1:-1]\n",
    "    print(choice)\n",
    "    if choice in optimal_choices:\n",
    "        eval_str = \"Correct as the choice is in the optimal choices\"\n",
    "    else:\n",
    "        print(prediction)\n",
    "        eval_str = f\"Incorrect as the choice is not in the optimal choices, LLM response: {choice}, optimal choices: '{', '.join(optimal_choices)}'.\"\n",
    "\n",
    "    eval = tg.Variable(eval_str, role_description=\"Evaluation of the prediction\", requires_grad=False)\n",
    "\n",
    "    loss = loss_fn(system_prompt, question, prediction, answer, eval)\n",
    "    losses.append(loss)\n",
    "    \n",
    "    if len(losses) == batch_size:\n",
    "        optimizer.zero_grad()\n",
    "        total_loss = tg.sum(losses)\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "        losses = []\n",
    "        with open(\"4o-improve_prompts.txt\", \"a\") as f:\n",
    "            f.write(system_prompt.value + \"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an expert in navigating articles with the goal of finding the shortest path from the start article to the target article by selecting the provided links. Your expertise involves understanding thematic, historical, geographical, cultural, economic, and social connections. Each time you will be given a (current article, destination) pair and the list of next articles you could choose from.\n",
      "\n",
      "Your output should include:\n",
      "- \"Choice: \" followed by the title of the article you want to navigate to.\n",
      "- \"Reason: \" followed by a specific and well-reasoned justification for your choice, considering direct connections and potential pathways to the target.\n",
      "\n",
      "Consider multiple potential paths and evaluate their merits before making a choice. Use the information provided and avoid relying on assumptions or external knowledge not present in the task. Reflect on your choices and learn from any mistakes to improve your navigation strategy. Emphasize the importance of minimizing steps and prioritize links that are part of the shortest path. Incorporate feedback from past decisions to refine your strategy and ensure efficient navigation.\n",
      "\n",
      "To enhance your decision-making:\n",
      "- Prioritize links with direct connections to the target article, especially those that are chronologically or geographically adjacent.\n",
      "- Evaluate potential links hierarchically, starting with the most specific and direct connections.\n",
      "- Balance thematic relevance with chronological proximity when considering potential links.\n",
      "- Hypothesize multiple potential paths and evaluate their likelihood of success using a structured decision-making framework.\n",
      "- Continuously refine your strategy based on feedback and past experiences.\n",
      "- Avoid common pitfalls such as over-reliance on broad thematic links or assumptions not supported by the provided data.\n",
      "- Test hypotheses about potential paths and adjust your strategy based on the outcomes.\n",
      "\n",
      "By following these guidelines, you will improve your ability to select the most efficient path to the target article.\n"
     ]
    }
   ],
   "source": [
    "print(system_prompt.__str__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/159 [00:06<17:55,  6.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for Brain to Telephone: 5.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 2/159 [00:21<29:42, 11.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for Theatre to Zebra: 7.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 3/159 [00:34<32:11, 12.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for Pyramid to Bean: 5.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 4/159 [00:41<26:21, 10.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for Batman to Wood: 5.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 5/159 [00:49<23:36,  9.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for Bird to Great_white_shark: 5.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 6/159 [00:56<21:41,  8.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for Batman to The_Holocaust: 4.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 7/159 [01:02<19:47,  7.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neighbors: ['18th_century', '19th_century', 'Anarchism', 'Anarcho-capitalism', 'Ancient_Greece', 'Aristotle', 'Augustus', 'Baruch_Spinoza', 'Bible', 'Capitalism', 'Civil_society', 'Communism', 'Confucius', 'Constitutional_monarchy', 'Corporation', 'David_Hume', 'Democracy', 'Edmund_Burke', 'Election', 'England', 'Ethics', 'Europe', 'Family', 'Force', 'France', 'French_Revolution', 'Government', 'Italy', 'Jean-Jacques_Rousseau', 'John_Locke', 'Karl_Marx', 'Karl_Popper', 'Liberal_democracy', 'Liberalism', 'Libertarianism', 'Marxism', 'Max_Weber', 'Monarchy', 'North_Korea', 'Oligarchy', 'Philosophy', 'Plato', 'Political_economy', 'Political_philosophy', 'Political_science', 'Religion', 'Renaissance', 'Roman_Empire', 'Society', 'Soviet_Union', 'Thomas_Hobbes', 'Thomas_Jefferson', 'United_States', 'Vladimir_Lenin', 'Voting', 'War']\n",
      "choice: Germany\n",
      "neighbors: ['18th_century', '19th_century', 'Anarchism', 'Anarcho-capitalism', 'Ancient_Greece', 'Aristotle', 'Augustus', 'Baruch_Spinoza', 'Bible', 'Capitalism', 'Civil_society', 'Communism', 'Confucius', 'Constitutional_monarchy', 'Corporation', 'David_Hume', 'Democracy', 'Edmund_Burke', 'Election', 'England', 'Ethics', 'Europe', 'Family', 'Force', 'France', 'French_Revolution', 'Government', 'Italy', 'Jean-Jacques_Rousseau', 'John_Locke', 'Karl_Marx', 'Karl_Popper', 'Liberal_democracy', 'Liberalism', 'Libertarianism', 'Marxism', 'Max_Weber', 'Monarchy', 'North_Korea', 'Oligarchy', 'Philosophy', 'Plato', 'Political_economy', 'Political_philosophy', 'Political_science', 'Religion', 'Renaissance', 'Roman_Empire', 'Society', 'Soviet_Union', 'Thomas_Hobbes', 'Thomas_Jefferson', 'United_States', 'Vladimir_Lenin', 'Voting', 'War']\n",
      "choice: Germany\n",
      "Average path length for Bird to Adolf_Hitler: No path found\n",
      "Invalid choices: 2, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 8/159 [01:11<20:44,  8.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for Beer to Sun: 6.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 9/159 [01:20<20:34,  8.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for Batman to Banana: 6.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 10/159 [01:23<16:43,  6.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for Cat to Computer: 3.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 11/159 [01:29<16:06,  6.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for Cat to Microsoft: 5.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 12/159 [01:38<17:48,  7.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for Dog to Telephone: 5.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 13/159 [01:43<16:06,  6.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for Flower to Adolf_Hitler: 4.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 14/159 [01:58<22:02,  9.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for Automobile to Pluto: 5.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 15/159 [02:26<35:19, 14.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for Dog to Venus: 11.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 16/159 [02:35<31:04, 13.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for Batman to Bible: 4.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 17/159 [02:44<28:06, 11.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for Aluminium_chloride to Parrot: 6.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█▏        | 18/159 [02:49<22:49,  9.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for England to God: 4.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 19/159 [02:56<20:37,  8.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for Achilles_tendon to Ocean: 5.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 20/159 [03:24<33:56, 14.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for Calculus to Paul_McCartney: 15.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 21/159 [03:35<31:12, 13.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for Aircraft to Google: 7.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 22/159 [03:42<26:16, 11.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for Electricity to God: 6.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 23/159 [03:52<25:43, 11.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for Art to Mango: 7.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 24/159 [04:00<22:40, 10.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for Brazil to Hydrogen: 5.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 25/159 [04:03<17:59,  8.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for Africa to England: 3.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 26/159 [04:10<17:25,  7.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neighbors: ['15th_century', 'Acts_of_Union_1707', 'Adam_Smith', 'Afghanistan', 'Africa', 'Akrotiri_and_Dhekelia', 'Algeria', 'Argentina', 'Atlantic_Ocean', 'Australia', 'Bangladesh', 'Barbados', 'Belgium', 'Benjamin_Disraeli,_1st_Earl_of_Beaconsfield', 'Botswana', 'British_East_India_Company', 'British_Isles', 'Cairo', 'Canada', 'Cape_Town', 'China', 'Cod', 'Cold_War', 'Congo_River', 'Cotton', 'Cricket', 'Crimean_War', 'Cyprus', 'Dante_Alighieri', 'Dublin', 'East_Africa', 'Egypt', 'Elizabeth_I_of_England', 'English_language', 'Ethiopia', 'Europe', 'Falkland_Islands', 'Ferdinand_Magellan', 'Football_(soccer)', 'France', 'Francis_Drake', 'Germany', 'Ghana', 'Gold', 'Great_Britain', 'Greece', 'Henry_VIII_of_England', 'Henry_VII_of_England', 'Hong_Kong', 'India', 'Indian_independence_movement', 'Industrial_Revolution', 'Iran', 'Iraq', 'Israel', 'Italy', 'Jamaica', 'James_I_of_England', 'Japan', 'Jew', 'John_Cabot', 'John_Dee', 'Kenya', 'Latin_America', 'Lesotho', 'Liberia', 'London', 'Mahatma_Gandhi', 'Malawi', 'Malaysia', 'Mercantilism', 'Middle_East', 'Myanmar', 'Namibia', 'Napoleon_I_of_France', 'Napoleonic_Wars', 'Nationalism', 'Netherlands', 'New_York_City', 'New_Zealand', 'Nigeria', 'Nile', 'North_America', 'Northern_Ireland', 'Ottawa', 'Ottoman_Empire', 'Pakistan', 'Panama', \"People's_Republic_of_China\", 'Portsmouth', 'Portugal', 'Race', 'Republic_of_Ireland', 'Rice', 'Richard_III_of_England', 'Rockall', 'Royal_Navy', 'Russia', 'Saint_Helena', 'Scotland', 'Second_Boer_War', 'Sierra_Leone', 'Singapore', 'Slavery', 'Society', 'South_Africa', 'Soviet_Union', 'Spain', 'Spanish_Armada', 'Sudan', 'Suez_Canal', 'Swaziland', 'Tea', 'The_Gambia', 'Tibet', 'Tobacco', 'Treaty_of_Versailles', 'Trinidad_and_Tobago', 'Turkey', 'Uganda', 'United_Kingdom', 'United_States', 'Victoria_of_the_United_Kingdom', 'Wales', 'Walter_Raleigh', 'World_War_I', 'World_War_II', 'Zambia', 'Zimbabwe']\n",
      "choice: French Indochina\n",
      "neighbors: ['15th_century', 'Acts_of_Union_1707', 'Adam_Smith', 'Afghanistan', 'Africa', 'Akrotiri_and_Dhekelia', 'Algeria', 'Argentina', 'Atlantic_Ocean', 'Australia', 'Bangladesh', 'Barbados', 'Belgium', 'Benjamin_Disraeli,_1st_Earl_of_Beaconsfield', 'Botswana', 'British_East_India_Company', 'British_Isles', 'Cairo', 'Canada', 'Cape_Town', 'China', 'Cod', 'Cold_War', 'Congo_River', 'Cotton', 'Cricket', 'Crimean_War', 'Cyprus', 'Dante_Alighieri', 'Dublin', 'East_Africa', 'Egypt', 'Elizabeth_I_of_England', 'English_language', 'Ethiopia', 'Europe', 'Falkland_Islands', 'Ferdinand_Magellan', 'Football_(soccer)', 'France', 'Francis_Drake', 'Germany', 'Ghana', 'Gold', 'Great_Britain', 'Greece', 'Henry_VIII_of_England', 'Henry_VII_of_England', 'Hong_Kong', 'India', 'Indian_independence_movement', 'Industrial_Revolution', 'Iran', 'Iraq', 'Israel', 'Italy', 'Jamaica', 'James_I_of_England', 'Japan', 'Jew', 'John_Cabot', 'John_Dee', 'Kenya', 'Latin_America', 'Lesotho', 'Liberia', 'London', 'Mahatma_Gandhi', 'Malawi', 'Malaysia', 'Mercantilism', 'Middle_East', 'Myanmar', 'Namibia', 'Napoleon_I_of_France', 'Napoleonic_Wars', 'Nationalism', 'Netherlands', 'New_York_City', 'New_Zealand', 'Nigeria', 'Nile', 'North_America', 'Northern_Ireland', 'Ottawa', 'Ottoman_Empire', 'Pakistan', 'Panama', \"People's_Republic_of_China\", 'Portsmouth', 'Portugal', 'Race', 'Republic_of_Ireland', 'Rice', 'Richard_III_of_England', 'Rockall', 'Royal_Navy', 'Russia', 'Saint_Helena', 'Scotland', 'Second_Boer_War', 'Sierra_Leone', 'Singapore', 'Slavery', 'Society', 'South_Africa', 'Soviet_Union', 'Spain', 'Spanish_Armada', 'Sudan', 'Suez_Canal', 'Swaziland', 'Tea', 'The_Gambia', 'Tibet', 'Tobacco', 'Treaty_of_Versailles', 'Trinidad_and_Tobago', 'Turkey', 'Uganda', 'United_Kingdom', 'United_States', 'Victoria_of_the_United_Kingdom', 'Wales', 'Walter_Raleigh', 'World_War_I', 'World_War_II', 'Zambia', 'Zimbabwe']\n",
      "choice: French Indochina\n",
      "Average path length for Archbishop_of_Canterbury to Vietnam: No path found\n",
      "Invalid choices: 2, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 27/159 [04:17<16:44,  7.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for Computer to Russia: 5.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 28/159 [04:23<15:05,  6.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for Computer to Fruit: 4.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 29/159 [04:30<15:05,  6.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for 14th_century to Rainbow: 5.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 30/159 [04:35<14:04,  6.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for Cat to Adolf_Hitler: 5.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 31/159 [04:36<10:31,  4.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for Jesus to God: 2.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 32/159 [04:43<11:28,  5.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for Manchester to Water: 5.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 33/159 [04:45<09:15,  4.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neighbors: ['Abacus', 'Africa', 'Amur', 'Ancient_Egypt', 'Architecture', 'Arctic', 'Badminton', 'Basketball', 'Beijing', 'Biology', 'Blaise_Pascal', 'Buddhism', 'Calligraphy', 'Carboniferous', 'Chinese_language', 'Christianity', 'Civilization', 'Climate', 'Clock', 'Confucianism', 'Constitutional_monarchy', 'Desert', 'Drought', 'Economics', 'English_language', 'Ethiopia', 'Football_(soccer)', 'Geography', 'Go_(board_game)', 'God', 'Great_Wall_of_China', 'Guangzhou', 'Gunpowder', 'Guqin', 'Himalayas', 'Hong_Kong', 'Hot_air_balloon', 'Human', 'Indonesia', 'Indus_Valley_Civilization', 'Islam', 'Japan', 'Jesus', 'Judaism', 'Korea', 'Laos', 'Macau', 'Malaysia', 'Mathematics', 'Maya_civilization', 'Mekong', 'Mesopotamia', 'Ming_Dynasty', 'Mongolia', 'Mount_Everest', 'Music', 'Musical_instrument', 'Myanmar', 'Pacific_Ocean', 'Painting', \"People's_Republic_of_China\", 'Pi', 'Portugal', 'Printmaking', 'Qin_Dynasty', 'Qing_Dynasty', 'Republic_of_China', 'River', 'Roman_Empire', 'Sea', 'Shanghai', 'Southern_Africa', 'Sumer', 'Sun_Yat-sen', 'Taipei', 'Taiwan', 'Taoism', 'Temperate', 'Terrorism', 'Tiananmen_Square_protests_of_1989', 'Tibet', 'United_Kingdom', 'United_Nations', 'United_States', 'Vietnam', 'Volcano', 'World_Health_Organization', 'World_War_II', 'Yangtze_River', 'Yellow_River']\n",
      "choice: Moon\n",
      "neighbors: ['Abacus', 'Africa', 'Amur', 'Ancient_Egypt', 'Architecture', 'Arctic', 'Badminton', 'Basketball', 'Beijing', 'Biology', 'Blaise_Pascal', 'Buddhism', 'Calligraphy', 'Carboniferous', 'Chinese_language', 'Christianity', 'Civilization', 'Climate', 'Clock', 'Confucianism', 'Constitutional_monarchy', 'Desert', 'Drought', 'Economics', 'English_language', 'Ethiopia', 'Football_(soccer)', 'Geography', 'Go_(board_game)', 'God', 'Great_Wall_of_China', 'Guangzhou', 'Gunpowder', 'Guqin', 'Himalayas', 'Hong_Kong', 'Hot_air_balloon', 'Human', 'Indonesia', 'Indus_Valley_Civilization', 'Islam', 'Japan', 'Jesus', 'Judaism', 'Korea', 'Laos', 'Macau', 'Malaysia', 'Mathematics', 'Maya_civilization', 'Mekong', 'Mesopotamia', 'Ming_Dynasty', 'Mongolia', 'Mount_Everest', 'Music', 'Musical_instrument', 'Myanmar', 'Pacific_Ocean', 'Painting', \"People's_Republic_of_China\", 'Pi', 'Portugal', 'Printmaking', 'Qin_Dynasty', 'Qing_Dynasty', 'Republic_of_China', 'River', 'Roman_Empire', 'Sea', 'Shanghai', 'Southern_Africa', 'Sumer', 'Sun_Yat-sen', 'Taipei', 'Taiwan', 'Taoism', 'Temperate', 'Terrorism', 'Tiananmen_Square_protests_of_1989', 'Tibet', 'United_Kingdom', 'United_Nations', 'United_States', 'Vietnam', 'Volcano', 'World_Health_Organization', 'World_War_II', 'Yangtze_River', 'Yellow_River']\n",
      "choice: Moon\n",
      "Average path length for China to Moon: No path found\n",
      "Invalid choices: 2, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 34/159 [04:52<10:54,  5.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for Antlion to Hip_hop_music: 5.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 35/159 [04:56<09:39,  4.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for Batman to Japan: 3.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 36/159 [05:01<10:00,  4.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neighbors: ['19th_century', 'Africa', 'Anatomy', 'Animal', 'Anthropology', 'Bacteria', 'Beetle', 'Binomial_nomenclature', 'Biodiversity', 'Biosphere', 'Botany', 'Carbon', 'Carbon_dioxide', 'Cell_(biology)', 'Charles_Darwin', 'Climate', 'Climate_change', 'Creation-evolution_controversy', 'DNA', 'Drosophila_melanogaster', 'Earth', 'Ecology', 'Eukaryote', 'Evolution', 'Extinction', 'Fern', 'Fossil', 'Fungus', 'Gazelle', 'Genetic_code', 'Genetics', 'Geology', 'Human', 'Latin', 'Life', 'Lion', 'Mathematics', 'Medicine', 'Microscope', 'Natural_selection', 'Organism', 'Paleontology', 'Plant', 'Plate_tectonics', 'Prion', 'Science', 'Scientific_classification', 'Statistics', 'Thermodynamics', 'Virus', 'William_Harvey', 'Yeast']\n",
      "choice: Vitamin_D\n",
      "neighbors: ['19th_century', 'Africa', 'Anatomy', 'Animal', 'Anthropology', 'Bacteria', 'Beetle', 'Binomial_nomenclature', 'Biodiversity', 'Biosphere', 'Botany', 'Carbon', 'Carbon_dioxide', 'Cell_(biology)', 'Charles_Darwin', 'Climate', 'Climate_change', 'Creation-evolution_controversy', 'DNA', 'Drosophila_melanogaster', 'Earth', 'Ecology', 'Eukaryote', 'Evolution', 'Extinction', 'Fern', 'Fossil', 'Fungus', 'Gazelle', 'Genetic_code', 'Genetics', 'Geology', 'Human', 'Latin', 'Life', 'Lion', 'Mathematics', 'Medicine', 'Microscope', 'Natural_selection', 'Organism', 'Paleontology', 'Plant', 'Plate_tectonics', 'Prion', 'Science', 'Scientific_classification', 'Statistics', 'Thermodynamics', 'Virus', 'William_Harvey', 'Yeast']\n",
      "choice: Vitamin_D\n",
      "Average path length for Batman to Vitamin_D: No path found\n",
      "Invalid choices: 2, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 37/159 [05:14<15:08,  7.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for Batman to Penguin: 8.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 38/159 [05:19<13:12,  6.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neighbors: ['16th_century', '4th_century', '5th_century', '7th_century', 'A_cappella', 'Anglican_Communion', 'Anglicanism', 'Atheism', 'Bible', 'Byzantine_Empire', 'Church_of_England', 'Crusades', 'Cultural_identity', 'East-West_Schism', 'Eastern_Orthodox_Church', 'Europe', 'First_Council_of_Nicaea', 'French_Revolution', 'Hebrew_language', 'Islam', 'Jew', 'John_Calvin', 'Judaism', 'Kosovo', 'Last_Supper', 'Latin_alphabet', 'Liberalism', 'Martin_Luther', 'Middle_Ages', 'Middle_East', 'Nationalism', 'North_Africa', 'North_Korea', 'Oceania', 'Ottoman_Empire', 'Paul_of_Tarsus', \"People's_Republic_of_China\", 'Philippines', 'Pope', 'Religion', 'Roman_Catholic_Church', 'Roman_Empire', 'Sermon_on_the_Mount', 'Socialism', 'Southern_Africa', 'Spain', 'Sub-Saharan_Africa', 'Sudan']\n",
      "choice: German Empire\n",
      "neighbors: ['16th_century', '4th_century', '5th_century', '7th_century', 'A_cappella', 'Anglican_Communion', 'Anglicanism', 'Atheism', 'Bible', 'Byzantine_Empire', 'Church_of_England', 'Crusades', 'Cultural_identity', 'East-West_Schism', 'Eastern_Orthodox_Church', 'Europe', 'First_Council_of_Nicaea', 'French_Revolution', 'Hebrew_language', 'Islam', 'Jew', 'John_Calvin', 'Judaism', 'Kosovo', 'Last_Supper', 'Latin_alphabet', 'Liberalism', 'Martin_Luther', 'Middle_Ages', 'Middle_East', 'Nationalism', 'North_Africa', 'North_Korea', 'Oceania', 'Ottoman_Empire', 'Paul_of_Tarsus', \"People's_Republic_of_China\", 'Philippines', 'Pope', 'Religion', 'Roman_Catholic_Church', 'Roman_Empire', 'Sermon_on_the_Mount', 'Socialism', 'Southern_Africa', 'Spain', 'Sub-Saharan_Africa', 'Sudan']\n",
      "choice: German Empire\n",
      "Average path length for Jesus to Adolf_Hitler: No path found\n",
      "Invalid choices: 2, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 39/159 [05:57<32:09, 16.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for Achilles_tendon to Ivory: 21.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 40/159 [06:03<25:59, 13.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neighbors: ['Abraham_Lincoln', 'Advertising', 'Agriculture', 'American_Civil_War', 'American_English', 'American_Revolutionary_War', 'American_Samoa', 'American_football', 'American_popular_music', 'Amtrak', 'Anguilla', 'Antarctica', 'Antigua_and_Barbuda', 'Apollo_11', 'Arctic_Ocean', 'Argentina', 'Aruba', 'Atlanta,_Georgia', 'Atlantic_Ocean', 'Attack_on_Pearl_Harbor', 'Auto_racing', \"Bahá'í_Faith\", 'Baker_Island', 'Bald_Eagle', 'Baltimore,_Maryland', 'Barbados', 'Baseball', 'Basketball', 'Battle_of_Gettysburg', 'Belize', 'Benin', 'Bermuda', 'Boston,_Massachusetts', 'Brazil', 'British_Virgin_Islands', 'Broadcasting', 'Brunei', 'Buddhism', \"Côte_d'Ivoire\", 'California', 'Cambodia', 'Cameroon', 'Canada', 'Cape_Verde', 'Capitalism', 'Caribbean_Sea', 'Cayman_Islands', 'Chicago', 'China', 'Chinese_language', 'Christopher_Columbus', 'Cinema_of_the_United_States', 'Coal', 'Cold_War', 'Colombia', 'Communism', 'Computer', 'Corporation', 'Costa_Rica', 'Country', 'Crime', 'Cuba', 'Currency', 'Dallas,_Texas', 'Denmark', 'Denver,_Colorado', 'Desert', 'Detroit,_Michigan', 'Dominica', 'Dominican_Republic', 'Ecuador', 'Education', 'Education_in_the_United_States', 'El_Salvador', 'Electronics', 'Elvis_Presley', 'Equatorial_Guinea', 'Erie_Canal', 'Ethnic_group', 'Europe', 'Federal_Bureau_of_Investigation', 'Federated_States_of_Micronesia', 'Film', 'Finance', 'Fine_art', 'Florida', 'Football_(soccer)', 'France', 'French_Guiana', 'French_language', 'Gabon', 'George_W._Bush', 'George_Washington', 'German_language', 'Germany', 'Ghana', 'Gibraltar', 'Grand_Canyon', 'Great_Lakes', 'Greece', 'Greenland', 'Grenada', 'Guadeloupe', 'Guam', 'Guatemala', 'Guernsey', 'Guinea', 'Guinea-Bissau', 'Gulf_of_Mexico', 'Guyana', 'Haiti', 'Hinduism', 'Hip_hop_music', 'History_of_slavery', 'Holy_Roman_Empire', 'Honduras', 'Hong_Kong', 'Household_income_in_the_United_States', 'Houston,_Texas', 'Howland_Island', 'Ice_hockey', 'Iceland', 'India', 'Indonesia', 'International_Red_Cross_and_Red_Crescent_Movement', 'Internet', 'Interpol', 'Iran', 'Iraq', 'Irish_people', 'Islam', 'Isle_of_Man', 'Italy', 'Jamaica', 'Japan', 'Jarvis_Island', 'Jazz', 'Jersey', 'John_F._Kennedy', 'Johnston_Atoll', 'Judaism', 'Kingman_Reef', 'Kiribati', 'Las_Vegas,_Nevada', 'Latin', 'Latin_America', 'Liberal_democracy', 'Liberia', 'List_of_areas_in_the_National_Park_System_of_the_United_States', 'List_of_countries', 'List_of_countries_by_system_of_government', 'List_of_rivers_by_length', 'List_of_sovereign_states', 'Los_Angeles,_California', 'Macau', 'Maize', 'Malaysia', 'Manifest_Destiny', 'Marshall_Islands', 'Martin_Luther_King,_Jr.', 'Martinique', 'Mauritania', 'Medicine', 'Mexico', 'Miami,_Florida', 'Middle_East', 'Midway_Atoll', 'Mining', 'Minneapolis,_Minnesota', 'Minnesota', 'Mississippi_River', 'Missouri_River', 'Montserrat', 'Moon', 'Morocco', 'Multiculturalism', 'Music_of_the_United_States', 'NATO', 'Natural_gas', 'Navassa_Island', 'Neil_Armstrong', 'Netherlands', 'Netherlands_Antilles', 'New_York_City', 'Nicaragua', 'Nigeria', 'North_Africa', 'North_America', 'North_Korea', 'Northern_Mariana_Islands', 'Nuclear_power', 'Nuclear_weapon', 'Oceania', 'Olympic_Games', 'Oregon', 'Pacific_Ocean', 'Palau', 'Palmyra_Atoll', 'Panama', 'Peace', \"People's_Republic_of_China\", 'Peru', 'Petroleum', 'Philadelphia', 'Philippines', 'Plymouth', 'Poetry_of_the_United_States', 'Poland', 'Portugal', 'Potato', 'President_of_the_United_States', 'Property', 'Publishing', 'Puerto_Rico', 'Qatar', 'Religious_Society_of_Friends', 'Republic_of_China', 'Republic_of_Ireland', 'Republic_of_the_Congo', 'Rhode_Island', 'Rhythm_and_blues', 'Rice', 'Rocky_Mountains', 'Russia', 'São_Tomé_and_Príncipe', 'Saint-Pierre_and_Miquelon', 'Saint_Kitts_and_Nevis', 'Saint_Lucia', 'Saint_Vincent_and_the_Grenadines', 'San_Francisco,_California', 'Seattle,_Washington', 'Senegal', 'September_11,_2001_attacks', 'Sequoia', 'Sierra_Leone', 'Sikhism', 'Singapore', 'Slovakia', 'South_Korea', 'Southern_United_States', 'Soviet_Union', 'Space_Shuttle_Columbia', 'Spain', 'Spanish_language', 'Sport', 'Steel', 'Sudan', 'Supreme_Court_of_the_United_States', 'Suriname', 'Sweden', 'Tanzania', 'Television', 'Tennis', 'Terrorism', 'Thailand', 'The_Bahamas', 'The_Gambia', 'Thomas_Jefferson', 'Time_zone', 'Togo', 'Tourism', 'Treaty_of_Versailles', 'Trinidad_and_Tobago', 'Turkey_(bird)', 'Turks_and_Caicos_Islands', 'U.S._state', 'United_Kingdom', 'United_Nations', 'United_States_Bill_of_Rights', 'United_States_Congress', 'United_States_Constitution', 'United_States_Declaration_of_Independence', 'United_States_House_of_Representatives', 'United_States_Senate', 'United_States_Virgin_Islands', 'United_States_dollar', 'Venezuela', 'Vietnam', 'Vietnam_War', 'Volcano', 'Wake_Island', 'Wall_Street', 'Walt_Whitman', 'War', 'Washington,_D.C.', 'West_Virginia', 'Western_Sahara', 'Wheat', 'World_Health_Organization', 'World_Heritage_Site', 'World_Trade_Organization', 'World_War_I', 'World_War_II', 'Yellowstone_National_Park']\n",
      "choice: Albert_Einstein\n",
      "neighbors: ['Abraham_Lincoln', 'Advertising', 'Agriculture', 'American_Civil_War', 'American_English', 'American_Revolutionary_War', 'American_Samoa', 'American_football', 'American_popular_music', 'Amtrak', 'Anguilla', 'Antarctica', 'Antigua_and_Barbuda', 'Apollo_11', 'Arctic_Ocean', 'Argentina', 'Aruba', 'Atlanta,_Georgia', 'Atlantic_Ocean', 'Attack_on_Pearl_Harbor', 'Auto_racing', \"Bahá'í_Faith\", 'Baker_Island', 'Bald_Eagle', 'Baltimore,_Maryland', 'Barbados', 'Baseball', 'Basketball', 'Battle_of_Gettysburg', 'Belize', 'Benin', 'Bermuda', 'Boston,_Massachusetts', 'Brazil', 'British_Virgin_Islands', 'Broadcasting', 'Brunei', 'Buddhism', \"Côte_d'Ivoire\", 'California', 'Cambodia', 'Cameroon', 'Canada', 'Cape_Verde', 'Capitalism', 'Caribbean_Sea', 'Cayman_Islands', 'Chicago', 'China', 'Chinese_language', 'Christopher_Columbus', 'Cinema_of_the_United_States', 'Coal', 'Cold_War', 'Colombia', 'Communism', 'Computer', 'Corporation', 'Costa_Rica', 'Country', 'Crime', 'Cuba', 'Currency', 'Dallas,_Texas', 'Denmark', 'Denver,_Colorado', 'Desert', 'Detroit,_Michigan', 'Dominica', 'Dominican_Republic', 'Ecuador', 'Education', 'Education_in_the_United_States', 'El_Salvador', 'Electronics', 'Elvis_Presley', 'Equatorial_Guinea', 'Erie_Canal', 'Ethnic_group', 'Europe', 'Federal_Bureau_of_Investigation', 'Federated_States_of_Micronesia', 'Film', 'Finance', 'Fine_art', 'Florida', 'Football_(soccer)', 'France', 'French_Guiana', 'French_language', 'Gabon', 'George_W._Bush', 'George_Washington', 'German_language', 'Germany', 'Ghana', 'Gibraltar', 'Grand_Canyon', 'Great_Lakes', 'Greece', 'Greenland', 'Grenada', 'Guadeloupe', 'Guam', 'Guatemala', 'Guernsey', 'Guinea', 'Guinea-Bissau', 'Gulf_of_Mexico', 'Guyana', 'Haiti', 'Hinduism', 'Hip_hop_music', 'History_of_slavery', 'Holy_Roman_Empire', 'Honduras', 'Hong_Kong', 'Household_income_in_the_United_States', 'Houston,_Texas', 'Howland_Island', 'Ice_hockey', 'Iceland', 'India', 'Indonesia', 'International_Red_Cross_and_Red_Crescent_Movement', 'Internet', 'Interpol', 'Iran', 'Iraq', 'Irish_people', 'Islam', 'Isle_of_Man', 'Italy', 'Jamaica', 'Japan', 'Jarvis_Island', 'Jazz', 'Jersey', 'John_F._Kennedy', 'Johnston_Atoll', 'Judaism', 'Kingman_Reef', 'Kiribati', 'Las_Vegas,_Nevada', 'Latin', 'Latin_America', 'Liberal_democracy', 'Liberia', 'List_of_areas_in_the_National_Park_System_of_the_United_States', 'List_of_countries', 'List_of_countries_by_system_of_government', 'List_of_rivers_by_length', 'List_of_sovereign_states', 'Los_Angeles,_California', 'Macau', 'Maize', 'Malaysia', 'Manifest_Destiny', 'Marshall_Islands', 'Martin_Luther_King,_Jr.', 'Martinique', 'Mauritania', 'Medicine', 'Mexico', 'Miami,_Florida', 'Middle_East', 'Midway_Atoll', 'Mining', 'Minneapolis,_Minnesota', 'Minnesota', 'Mississippi_River', 'Missouri_River', 'Montserrat', 'Moon', 'Morocco', 'Multiculturalism', 'Music_of_the_United_States', 'NATO', 'Natural_gas', 'Navassa_Island', 'Neil_Armstrong', 'Netherlands', 'Netherlands_Antilles', 'New_York_City', 'Nicaragua', 'Nigeria', 'North_Africa', 'North_America', 'North_Korea', 'Northern_Mariana_Islands', 'Nuclear_power', 'Nuclear_weapon', 'Oceania', 'Olympic_Games', 'Oregon', 'Pacific_Ocean', 'Palau', 'Palmyra_Atoll', 'Panama', 'Peace', \"People's_Republic_of_China\", 'Peru', 'Petroleum', 'Philadelphia', 'Philippines', 'Plymouth', 'Poetry_of_the_United_States', 'Poland', 'Portugal', 'Potato', 'President_of_the_United_States', 'Property', 'Publishing', 'Puerto_Rico', 'Qatar', 'Religious_Society_of_Friends', 'Republic_of_China', 'Republic_of_Ireland', 'Republic_of_the_Congo', 'Rhode_Island', 'Rhythm_and_blues', 'Rice', 'Rocky_Mountains', 'Russia', 'São_Tomé_and_Príncipe', 'Saint-Pierre_and_Miquelon', 'Saint_Kitts_and_Nevis', 'Saint_Lucia', 'Saint_Vincent_and_the_Grenadines', 'San_Francisco,_California', 'Seattle,_Washington', 'Senegal', 'September_11,_2001_attacks', 'Sequoia', 'Sierra_Leone', 'Sikhism', 'Singapore', 'Slovakia', 'South_Korea', 'Southern_United_States', 'Soviet_Union', 'Space_Shuttle_Columbia', 'Spain', 'Spanish_language', 'Sport', 'Steel', 'Sudan', 'Supreme_Court_of_the_United_States', 'Suriname', 'Sweden', 'Tanzania', 'Television', 'Tennis', 'Terrorism', 'Thailand', 'The_Bahamas', 'The_Gambia', 'Thomas_Jefferson', 'Time_zone', 'Togo', 'Tourism', 'Treaty_of_Versailles', 'Trinidad_and_Tobago', 'Turkey_(bird)', 'Turks_and_Caicos_Islands', 'U.S._state', 'United_Kingdom', 'United_Nations', 'United_States_Bill_of_Rights', 'United_States_Congress', 'United_States_Constitution', 'United_States_Declaration_of_Independence', 'United_States_House_of_Representatives', 'United_States_Senate', 'United_States_Virgin_Islands', 'United_States_dollar', 'Venezuela', 'Vietnam', 'Vietnam_War', 'Volcano', 'Wake_Island', 'Wall_Street', 'Walt_Whitman', 'War', 'Washington,_D.C.', 'West_Virginia', 'Western_Sahara', 'Wheat', 'World_Health_Organization', 'World_Heritage_Site', 'World_Trade_Organization', 'World_War_I', 'World_War_II', 'Yellowstone_National_Park']\n",
      "choice: Albert_Einstein\n",
      "Average path length for Batman to Albert_Einstein: No path found\n",
      "Invalid choices: 2, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 41/159 [06:11<22:17, 11.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for Brothers_Grimm to Windows_Vista: 6.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▋       | 42/159 [06:20<21:07, 10.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for Calculus to Lemon: 6.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 43/159 [06:27<18:45,  9.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for California to Adolf_Hitler: 4.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 44/159 [06:39<19:52, 10.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for Computer_programming to Fresh_water: 8.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 45/159 [06:52<20:49, 10.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for Automobile to Windows_XP: 6.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 46/159 [06:53<15:09,  8.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for Cat to Dog: 2.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 47/159 [06:55<12:01,  6.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for Apple to Banana: 3.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 48/159 [07:01<11:16,  6.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for China to Afghanistan: 4.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 49/159 [07:10<12:57,  7.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for God to Adolf_Hitler: 5.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███▏      | 50/159 [07:18<13:12,  7.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for Linux to Adolf_Hitler: 5.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 51/159 [07:20<10:25,  5.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for Moon to Mars: 2.0\n",
      "Invalid choices: 0, No path found: 0\n",
      "Average path length for Apple to Fruit: 2.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 53/159 [07:31<09:47,  5.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for Bamako to Sun: 7.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 54/159 [07:35<09:06,  5.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neighbors: ['Agriculture', 'Allosaurus', 'Anatomy', 'Ape', 'Archaeopteryx', 'Armadillo', 'Arthropod', 'Baboon', 'Bacteria', 'Biodiversity', 'Bioinformatics', 'Biology', 'Bird', 'Birth_control', 'Cambrian_explosion', 'Cancer', 'Cell_(biology)', 'Charles_Darwin', 'Chimpanzee', 'Computer', 'Creation-evolution_controversy', 'Creationism', 'Cretaceous-Tertiary_extinction_event', 'Crystal', 'DNA', 'Dinosaur', 'Ecology', 'Empiricism', 'Entropy', 'Eukaryote', 'Extinction', 'Fish', 'Fossil', 'Fossil_record', 'Francis_Crick', 'Galápagos_Islands', 'Genetic_code', 'Genetics', 'Geology', 'Glacier_National_Park_(US)', 'Gorilla', 'Gravitation', 'Gregor_Mendel', 'History_of_Earth', 'Ice_age', 'James_D._Watson', 'Judaism', 'Life', 'Malaria', 'Mineral', 'Mitochondrion', 'Natural_selection', 'Organism', 'Paleontology', 'Pea', 'Photosynthesis', 'Plant', 'Precambrian', 'Prion', 'Protein', 'Punctuated_equilibrium', 'Rain', 'Science', 'Sociology', 'South_America', 'Stephen_Jay_Gould', 'The_Origin_of_Species', 'Tiktaalik', 'United_States', 'Vertebrate', 'Vestigial_structure']\n",
      "choice: Astronomy\n",
      "neighbors: ['Agriculture', 'Allosaurus', 'Anatomy', 'Ape', 'Archaeopteryx', 'Armadillo', 'Arthropod', 'Baboon', 'Bacteria', 'Biodiversity', 'Bioinformatics', 'Biology', 'Bird', 'Birth_control', 'Cambrian_explosion', 'Cancer', 'Cell_(biology)', 'Charles_Darwin', 'Chimpanzee', 'Computer', 'Creation-evolution_controversy', 'Creationism', 'Cretaceous-Tertiary_extinction_event', 'Crystal', 'DNA', 'Dinosaur', 'Ecology', 'Empiricism', 'Entropy', 'Eukaryote', 'Extinction', 'Fish', 'Fossil', 'Fossil_record', 'Francis_Crick', 'Galápagos_Islands', 'Genetic_code', 'Genetics', 'Geology', 'Glacier_National_Park_(US)', 'Gorilla', 'Gravitation', 'Gregor_Mendel', 'History_of_Earth', 'Ice_age', 'James_D._Watson', 'Judaism', 'Life', 'Malaria', 'Mineral', 'Mitochondrion', 'Natural_selection', 'Organism', 'Paleontology', 'Pea', 'Photosynthesis', 'Plant', 'Precambrian', 'Prion', 'Protein', 'Punctuated_equilibrium', 'Rain', 'Science', 'Sociology', 'South_America', 'Stephen_Jay_Gould', 'The_Origin_of_Species', 'Tiktaalik', 'United_States', 'Vertebrate', 'Vestigial_structure']\n",
      "choice: Astronomy\n",
      "Average path length for Bird_migration to Hubble_Space_Telescope: No path found\n",
      "Invalid choices: 2, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 55/159 [07:42<09:56,  5.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for Jew to Telephone: 5.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 56/159 [07:47<09:34,  5.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for Video to China: 4.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 57/159 [07:56<10:52,  6.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for Famine to Arctic: 6.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▋      | 58/159 [08:07<12:54,  7.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for AIDS to Jesus: 6.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 59/159 [08:26<18:32, 11.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for George_W._Bush to Monkey: 11.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 60/159 [08:33<16:05,  9.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for Human to Pluto: 4.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 61/159 [09:02<25:29, 15.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for Smog to Toy_Story: 9.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 62/159 [09:07<20:02, 12.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for Pikachu to Sun: 6.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 63/159 [09:21<20:31, 12.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for Earth to Odysseus: 5.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 64/159 [09:29<17:56, 11.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for 15th_century to Windows_Vista: 5.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 65/159 [09:42<18:32, 11.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for Batman to Peanut: 7.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 66/159 [09:49<16:02, 10.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for Bird to Thomas_Jefferson: 5.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 67/159 [09:54<13:29,  8.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for Chemistry to Fidel_Castro: 4.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 68/159 [09:55<10:01,  6.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for Dinosaur to China: 2.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 69/159 [09:59<08:48,  5.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neighbors: ['16th_century', '17th_century', '18th_century', '19th_century', '20th_century', 'Ancient_Greece', 'Anthropology', 'Art', 'Astronomy', 'Berlin', 'Biosphere', 'Botany', 'Capitalism', 'Christopher_Columbus', 'Climate', 'Communication', 'Computer_science', 'Earth', \"Earth's_atmosphere\", 'Earthquake', 'Economics', 'Europe', 'Geology', 'Glaciology', 'Human', 'Hydrology', 'Immanuel_Kant', 'James_Cook', 'Logistics', 'Marco_Polo', 'Mathematics', 'Middle_Ages', 'Oceanography', 'Paris', 'Petroleum', 'Ptolemy', 'Pythagoras', 'Roman_Empire', 'Royal_Geographical_Society', 'Science', 'Sociology', 'Soil', 'Solar_System', 'Transport', 'University', 'Vegetation', 'Water']\n",
      "choice: Asia\n",
      "neighbors: ['16th_century', '17th_century', '18th_century', '19th_century', '20th_century', 'Ancient_Greece', 'Anthropology', 'Art', 'Astronomy', 'Berlin', 'Biosphere', 'Botany', 'Capitalism', 'Christopher_Columbus', 'Climate', 'Communication', 'Computer_science', 'Earth', \"Earth's_atmosphere\", 'Earthquake', 'Economics', 'Europe', 'Geology', 'Glaciology', 'Human', 'Hydrology', 'Immanuel_Kant', 'James_Cook', 'Logistics', 'Marco_Polo', 'Mathematics', 'Middle_Ages', 'Oceanography', 'Paris', 'Petroleum', 'Ptolemy', 'Pythagoras', 'Roman_Empire', 'Royal_Geographical_Society', 'Science', 'Sociology', 'Soil', 'Solar_System', 'Transport', 'University', 'Vegetation', 'Water']\n",
      "choice: Asia\n",
      "Average path length for John_Dee to China: No path found\n",
      "Invalid choices: 2, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 70/159 [10:05<08:43,  5.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for Reptile to Jesus: 5.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 71/159 [10:11<08:39,  5.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for United_States to English_language: 4.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 72/159 [10:15<07:25,  5.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for Adolf_Hitler to Jesus: 3.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 73/159 [10:16<05:39,  3.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for Mario to Nintendo: 2.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 74/159 [10:21<06:08,  4.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for Pikachu to Jesus: 5.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 75/159 [10:23<05:12,  3.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neighbors: ['Abidjan', 'Abuja', 'Accra', 'Addis_Ababa', 'African_Great_Lakes', 'African_Union', 'Afrikaans', 'Agriculture', 'Algeria', 'Algiers', 'Ancient_Egypt', 'Ancient_Greece', 'Ancient_Rome', 'Anglican_Communion', 'Angola', 'Antananarivo', 'Anthropology', 'Arabic_language', 'Asia', 'Atlantic_Ocean', 'Atlantic_slave_trade', 'Bamako', 'Banjul', 'Bantu', 'Belgium', 'Benin', 'Bissau', 'Botswana', 'Burkina_Faso', 'Burundi', \"Côte_d'Ivoire\", 'Cairo', 'Camel', 'Cameroon', 'Cape_Town', 'Cape_Verde', 'Capital', 'Carnivore', 'Central_African_Republic', 'Chad', 'Cheetah', 'China', 'Christianity', 'Civilization', 'Cocoa', 'Coffee', 'Cold_War', 'Comoros', 'Conakry', 'Congo_River', 'Continent', 'Cotton', 'Crocodile', 'Culture', 'Dakar', 'David_Livingstone', 'Deity', 'Democracy', 'Democratic_Republic_of_the_Congo', 'Desert', 'Despotism', 'Diamond', 'Djibouti', 'Earth', 'East_Africa', 'Egypt', 'El_Aaiún', 'Elephant', 'English_language', 'Equatorial_Guinea', 'Eritrea', 'Ethiopia', 'Europe', 'Famine', 'Flute', 'Fossil', 'France', 'Freetown', 'French_language', 'Funchal', 'Gabon', 'Gaborone', 'Ghana', 'Giraffe', 'Glacier', 'Gold', 'Great_Pyramid_of_Giza', 'Guinea', 'Guinea-Bissau', 'HIV', 'Harare', 'Henry_Morton_Stanley', 'Herbivore', 'Horn_of_Africa', 'Human', 'Hutu', 'Hyena', 'India', 'Indian_Ocean', 'Irrigation', 'Ishango_bone', 'Islam', 'Jazz', 'Judaism', 'Kenya', 'Khartoum', 'Kigali', 'Lake_Tanganyika', 'Lake_Victoria', 'Language', 'Las_Palmas_de_Gran_Canaria', 'Latin', 'Latin_America', 'Lesotho', 'Liberal_democracy', 'Liberia', 'Libreville', 'Libya', 'Lilongwe', 'Lion', 'Lomé', 'Lusaka', 'Madagascar', 'Malawi', 'Mali', 'Maputo', 'Maseru', 'Mauritania', 'Mauritius', 'Mayotte', 'Mbabane', 'Mediterranean_Sea', 'Middle_Ages', 'Military_dictatorship', 'Mitochondrial_Eve', 'Mogadishu', 'Monrovia', 'Morocco', 'Mozambique', 'Nairobi', 'Namibia', 'Netherlands', 'Niger', 'Nigeria', 'Nile', 'North_Africa', 'Nouakchott', 'Ouagadougou', 'Palm_oil', 'Persian_Empire', 'Pope', 'Port_Louis', 'Porto-Novo', 'Portugal', 'Portuguese_language', 'Poverty', 'Praia', 'Pretoria', 'Ptolemy', 'Réunion', 'Rabat', 'Rainforest', 'Red_Sea', 'Reggae', 'Republic_of_the_Congo', 'Rice', 'Richard_Francis_Burton', 'Royal_Navy', 'Rwanda', 'São_Tomé', 'São_Tomé_and_Príncipe', 'Saint_Helena', 'Scramble_for_Africa', 'Second_Congo_War', 'Senegal', 'Seychelles', 'Sierra_Leone', 'Somalia', 'Sorghum', 'Soukous', 'South_Africa', 'Southern_Africa', 'Soviet_Union', 'Spain', 'Sub-Saharan_Africa', 'Sudan', 'Suez_Canal', 'Swaziland', 'Tanzania', 'Temperate', 'The_Gambia', 'Timbuktu', 'Togo', 'Tripoli', 'Trumpet', 'Tunis', 'Tunisia', 'Tutsi', 'Uganda', 'United_Kingdom', 'United_Nations', 'United_States', 'United_States_Senate', 'Victoria,_Seychelles', 'Western_Sahara', 'World_War_I', 'World_War_II', 'Yamoussoukro', 'Zambia', 'Zheng_He', 'Zimbabwe', 'Zulu']\n",
      "choice: Mathematics\n",
      "neighbors: ['Abidjan', 'Abuja', 'Accra', 'Addis_Ababa', 'African_Great_Lakes', 'African_Union', 'Afrikaans', 'Agriculture', 'Algeria', 'Algiers', 'Ancient_Egypt', 'Ancient_Greece', 'Ancient_Rome', 'Anglican_Communion', 'Angola', 'Antananarivo', 'Anthropology', 'Arabic_language', 'Asia', 'Atlantic_Ocean', 'Atlantic_slave_trade', 'Bamako', 'Banjul', 'Bantu', 'Belgium', 'Benin', 'Bissau', 'Botswana', 'Burkina_Faso', 'Burundi', \"Côte_d'Ivoire\", 'Cairo', 'Camel', 'Cameroon', 'Cape_Town', 'Cape_Verde', 'Capital', 'Carnivore', 'Central_African_Republic', 'Chad', 'Cheetah', 'China', 'Christianity', 'Civilization', 'Cocoa', 'Coffee', 'Cold_War', 'Comoros', 'Conakry', 'Congo_River', 'Continent', 'Cotton', 'Crocodile', 'Culture', 'Dakar', 'David_Livingstone', 'Deity', 'Democracy', 'Democratic_Republic_of_the_Congo', 'Desert', 'Despotism', 'Diamond', 'Djibouti', 'Earth', 'East_Africa', 'Egypt', 'El_Aaiún', 'Elephant', 'English_language', 'Equatorial_Guinea', 'Eritrea', 'Ethiopia', 'Europe', 'Famine', 'Flute', 'Fossil', 'France', 'Freetown', 'French_language', 'Funchal', 'Gabon', 'Gaborone', 'Ghana', 'Giraffe', 'Glacier', 'Gold', 'Great_Pyramid_of_Giza', 'Guinea', 'Guinea-Bissau', 'HIV', 'Harare', 'Henry_Morton_Stanley', 'Herbivore', 'Horn_of_Africa', 'Human', 'Hutu', 'Hyena', 'India', 'Indian_Ocean', 'Irrigation', 'Ishango_bone', 'Islam', 'Jazz', 'Judaism', 'Kenya', 'Khartoum', 'Kigali', 'Lake_Tanganyika', 'Lake_Victoria', 'Language', 'Las_Palmas_de_Gran_Canaria', 'Latin', 'Latin_America', 'Lesotho', 'Liberal_democracy', 'Liberia', 'Libreville', 'Libya', 'Lilongwe', 'Lion', 'Lomé', 'Lusaka', 'Madagascar', 'Malawi', 'Mali', 'Maputo', 'Maseru', 'Mauritania', 'Mauritius', 'Mayotte', 'Mbabane', 'Mediterranean_Sea', 'Middle_Ages', 'Military_dictatorship', 'Mitochondrial_Eve', 'Mogadishu', 'Monrovia', 'Morocco', 'Mozambique', 'Nairobi', 'Namibia', 'Netherlands', 'Niger', 'Nigeria', 'Nile', 'North_Africa', 'Nouakchott', 'Ouagadougou', 'Palm_oil', 'Persian_Empire', 'Pope', 'Port_Louis', 'Porto-Novo', 'Portugal', 'Portuguese_language', 'Poverty', 'Praia', 'Pretoria', 'Ptolemy', 'Réunion', 'Rabat', 'Rainforest', 'Red_Sea', 'Reggae', 'Republic_of_the_Congo', 'Rice', 'Richard_Francis_Burton', 'Royal_Navy', 'Rwanda', 'São_Tomé', 'São_Tomé_and_Príncipe', 'Saint_Helena', 'Scramble_for_Africa', 'Second_Congo_War', 'Senegal', 'Seychelles', 'Sierra_Leone', 'Somalia', 'Sorghum', 'Soukous', 'South_Africa', 'Southern_Africa', 'Soviet_Union', 'Spain', 'Sub-Saharan_Africa', 'Sudan', 'Suez_Canal', 'Swaziland', 'Tanzania', 'Temperate', 'The_Gambia', 'Timbuktu', 'Togo', 'Tripoli', 'Trumpet', 'Tunis', 'Tunisia', 'Tutsi', 'Uganda', 'United_Kingdom', 'United_Nations', 'United_States', 'United_States_Senate', 'Victoria,_Seychelles', 'Western_Sahara', 'World_War_I', 'World_War_II', 'Yamoussoukro', 'Zambia', 'Zheng_He', 'Zimbabwe', 'Zulu']\n",
      "choice: Mathematics\n",
      "Average path length for Africa to Differential_equation: No path found\n",
      "Invalid choices: 2, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 76/159 [10:34<07:55,  5.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for Cat to University: 5.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 77/159 [10:40<07:51,  5.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for Citrus to Physics: 4.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 78/159 [10:51<09:56,  7.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neighbors: ['Aircraft', 'Alternating_current', 'Atom', 'Bible', 'Bluetooth', 'DVD', 'Detroit,_Michigan', 'Electric_charge', 'Electricity', 'Electromagnetic_radiation', 'Electron', 'England', 'Guglielmo_Marconi', 'Iron', 'Isle_of_Wight', 'Kolkata', 'Light', 'Nikola_Tesla', 'Philadelphia', 'Photon', 'RMS_Titanic', 'Radar', 'Radio_frequency', 'San_Jose,_California', 'Sony', 'Spacecraft_propulsion', 'Television', 'Ultraviolet', 'United_Kingdom', 'Woodrow_Wilson', 'World_War_I']\n",
      "choice: Guglielmo Marconi\n",
      "neighbors: ['Aircraft', 'Alternating_current', 'Atom', 'Bible', 'Bluetooth', 'DVD', 'Detroit,_Michigan', 'Electric_charge', 'Electricity', 'Electromagnetic_radiation', 'Electron', 'England', 'Guglielmo_Marconi', 'Iron', 'Isle_of_Wight', 'Kolkata', 'Light', 'Nikola_Tesla', 'Philadelphia', 'Photon', 'RMS_Titanic', 'Radar', 'Radio_frequency', 'San_Jose,_California', 'Sony', 'Spacecraft_propulsion', 'Television', 'Ultraviolet', 'United_Kingdom', 'Woodrow_Wilson', 'World_War_I']\n",
      "choice: Guglielmo Marconi\n",
      "Average path length for Computer to Whale: No path found\n",
      "Invalid choices: 2, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████▉     | 79/159 [10:56<08:56,  6.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for Dinosaur to George_W._Bush: 4.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 80/159 [11:07<10:28,  7.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for England to Train: 6.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 81/159 [11:08<07:45,  5.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for North_America to Canada: 2.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 82/159 [11:39<17:23, 13.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neighbors: ['18th_century', 'Africa', 'Albania', 'Amsterdam', 'Ancient_Greece', 'Andorra', 'Anglicanism', 'Arabic_language', 'Arctic_Ocean', 'Armenia', 'Asia', 'Athens', 'Atlantic_Ocean', 'Austria', 'Azerbaijan', 'Baltic_Sea', 'Barcelona', 'Belarus', 'Belgium', 'Berlin', 'Berlin_Wall', 'Black_Sea', 'Bosnia_and_Herzegovina', 'Bratislava', 'British_Isles', 'Brussels', 'Bucharest', 'Budapest', 'Buddhism', 'Bulgaria', 'Byzantine_Empire', 'Capital', 'Carnivore', 'Caspian_Sea', 'Christianity', 'Cold_War', 'Communism', 'Copenhagen', 'Croatia', 'Crustacean', 'Culture', 'Cyprus', 'Czech_Republic', 'Dark_Ages', 'Democracy', 'Denmark', 'Dolphin', 'Dublin', 'Earth', 'England', 'Estonia', 'European_Union', 'Faroe_Islands', 'Finland', 'Fish', 'Flanders', 'Forest', 'Fox', 'France', 'French_Revolution', 'French_language', 'Geology', 'Georgia_(country)', 'Germany', 'Gibraltar', 'Greece', 'Greenland', 'Guernsey', 'Hawk', 'Hebrew_language', 'Helsinki', 'Herbivore', 'Holy_Roman_Empire', 'Homer', 'Hungary', 'Ice_age', 'Iceland', 'Industrial_Revolution', 'Iran', 'Iraq', 'Ireland', 'Islam', 'Isle_of_Man', 'Jackal', 'Jersey', 'Judaism', 'Kazakhstan', 'Kiev', 'Kosovo', 'Latin', 'Latvia', 'Liechtenstein', 'Lisbon', 'Lithuania', 'London', 'Luxembourg', 'Luxembourg_(city)', 'Madrid', 'Malta', 'Mammal', 'Mediterranean_Sea', 'Middle_Ages', 'Middle_East', 'Moldova', 'Monaco', 'Montenegro', 'Moscow', 'NATO', 'Napoleon_I_of_France', 'Netherlands', 'North_America', 'North_Sea', 'Northern_Ireland', 'Norway', 'Oslo', 'Ottoman_Empire', 'Owl', 'Paris', 'Poland', 'Portugal', 'Prague', 'Rainforest', 'Renaissance', 'Republic_of_Ireland', 'Republic_of_Macedonia', 'Romania', 'Rome', 'Russia', 'San_Marino', 'Sarajevo', 'Scotland', 'Serbia', 'Sikhism', 'Slovakia', 'Slovenia', 'Soviet_Union', 'Spain', 'Stockholm', 'Suez_Canal', 'Svalbard', 'Sweden', 'Switzerland', 'Syria', 'Turkey', 'Turkish_Republic_of_Northern_Cyprus', 'Ukraine', 'United_Kingdom', 'United_Nations', 'Vatican_City', 'Vienna', 'Wales', 'Warsaw', 'Wild_cat', 'World_War_II', 'Zeus']\n",
      "choice: Neptune\n",
      "neighbors: ['18th_century', 'Africa', 'Albania', 'Amsterdam', 'Ancient_Greece', 'Andorra', 'Anglicanism', 'Arabic_language', 'Arctic_Ocean', 'Armenia', 'Asia', 'Athens', 'Atlantic_Ocean', 'Austria', 'Azerbaijan', 'Baltic_Sea', 'Barcelona', 'Belarus', 'Belgium', 'Berlin', 'Berlin_Wall', 'Black_Sea', 'Bosnia_and_Herzegovina', 'Bratislava', 'British_Isles', 'Brussels', 'Bucharest', 'Budapest', 'Buddhism', 'Bulgaria', 'Byzantine_Empire', 'Capital', 'Carnivore', 'Caspian_Sea', 'Christianity', 'Cold_War', 'Communism', 'Copenhagen', 'Croatia', 'Crustacean', 'Culture', 'Cyprus', 'Czech_Republic', 'Dark_Ages', 'Democracy', 'Denmark', 'Dolphin', 'Dublin', 'Earth', 'England', 'Estonia', 'European_Union', 'Faroe_Islands', 'Finland', 'Fish', 'Flanders', 'Forest', 'Fox', 'France', 'French_Revolution', 'French_language', 'Geology', 'Georgia_(country)', 'Germany', 'Gibraltar', 'Greece', 'Greenland', 'Guernsey', 'Hawk', 'Hebrew_language', 'Helsinki', 'Herbivore', 'Holy_Roman_Empire', 'Homer', 'Hungary', 'Ice_age', 'Iceland', 'Industrial_Revolution', 'Iran', 'Iraq', 'Ireland', 'Islam', 'Isle_of_Man', 'Jackal', 'Jersey', 'Judaism', 'Kazakhstan', 'Kiev', 'Kosovo', 'Latin', 'Latvia', 'Liechtenstein', 'Lisbon', 'Lithuania', 'London', 'Luxembourg', 'Luxembourg_(city)', 'Madrid', 'Malta', 'Mammal', 'Mediterranean_Sea', 'Middle_Ages', 'Middle_East', 'Moldova', 'Monaco', 'Montenegro', 'Moscow', 'NATO', 'Napoleon_I_of_France', 'Netherlands', 'North_America', 'North_Sea', 'Northern_Ireland', 'Norway', 'Oslo', 'Ottoman_Empire', 'Owl', 'Paris', 'Poland', 'Portugal', 'Prague', 'Rainforest', 'Renaissance', 'Republic_of_Ireland', 'Republic_of_Macedonia', 'Romania', 'Rome', 'Russia', 'San_Marino', 'Sarajevo', 'Scotland', 'Serbia', 'Sikhism', 'Slovakia', 'Slovenia', 'Soviet_Union', 'Spain', 'Stockholm', 'Suez_Canal', 'Svalbard', 'Sweden', 'Switzerland', 'Syria', 'Turkey', 'Turkish_Republic_of_Northern_Cyprus', 'Ukraine', 'United_Kingdom', 'United_Nations', 'Vatican_City', 'Vienna', 'Wales', 'Warsaw', 'Wild_cat', 'World_War_II', 'Zeus']\n",
      "choice: Neptune\n",
      "Average path length for The_Godfather to Neptune: No path found\n",
      "Invalid choices: 2, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 83/159 [12:05<21:58, 17.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for Volcano to Alphabet: 15.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 84/159 [12:11<17:05, 13.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for Nintendo to Snow: 4.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 85/159 [12:14<13:15, 10.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for Bangladesh to Harry_S._Truman: 3.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 86/159 [12:22<11:59,  9.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for Computer to Baseball: 5.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 87/159 [12:34<12:30, 10.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for Electricity to Anne_Frank: 7.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 88/159 [12:41<11:07,  9.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for Achilles to Winston_Churchill: 5.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 89/159 [12:59<13:51, 11.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for Aircraft to Yugoslavia: 5.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 90/159 [13:04<11:25,  9.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for AT%26T to Vegetable: 4.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 91/159 [13:11<10:11,  9.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for Batman to Jesus: 5.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 92/159 [13:16<08:38,  7.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for Beer to Warsaw: 4.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 93/159 [13:20<07:20,  6.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for Colombia to Meat: 4.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 94/159 [13:30<08:15,  7.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for Dog to Sea: 7.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 95/159 [13:37<07:53,  7.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for England to Japan: 4.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 96/159 [13:46<08:17,  7.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for Linguistics to Rome: 6.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 97/159 [14:05<11:50, 11.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for Metal to Prague: 9.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 98/159 [14:16<11:14, 11.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for Jesus to Google: 9.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 99/159 [14:25<10:28, 10.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for History to Nazi_Germany: 5.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 100/159 [14:43<12:38, 12.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for Fourteenth_Amendment_to_the_United_States_Constitution to Reptile: 7.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▎   | 101/159 [14:46<09:33,  9.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for Arnold_Schwarzenegger to Vegetable: 3.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 102/159 [14:53<08:33,  9.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for Google to God: 5.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 103/159 [14:59<07:36,  8.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for Harry_Potter to Kangaroo: 5.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 104/159 [15:10<08:16,  9.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for Acceleration to Mozilla_Firefox: 7.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 105/159 [15:14<06:43,  7.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neighbors: ['Africa', 'Alcohol', 'Ammonia', 'Andes', 'Arable_land', 'Barley', 'Beekeeping', 'Biodiesel', 'Botany', 'Cereal', 'Cocoa', 'Coffee', 'Cotton', 'Egg_(food)', 'Egypt', 'Ethanol', 'Fertile_Crescent', 'Fertilizer', 'Fish', 'Flower', 'Food', 'Fossil_fuel', 'France', 'Fruit', 'Germany', 'Global_warming', 'History_of_the_world', 'Honey', 'Horse', 'Indonesia', 'Irrigation', 'Maize', 'Meat', 'Mesopotamia', 'Middle_Ages', 'Milk', 'Nitrogen', 'Nutrition', 'Pea', 'Phosphorus', 'Potato', 'Rice', 'River', 'Soil', 'Soil_salination', 'Sorghum', 'South_America', 'Soybean', 'Sugar', 'Sumer', 'Sweden', 'Tea', 'Tobacco', 'Vegetable', 'Virgil', 'Weed', 'Wheat']\n",
      "choice: Bird\n",
      "neighbors: ['Africa', 'Alcohol', 'Ammonia', 'Andes', 'Arable_land', 'Barley', 'Beekeeping', 'Biodiesel', 'Botany', 'Cereal', 'Cocoa', 'Coffee', 'Cotton', 'Egg_(food)', 'Egypt', 'Ethanol', 'Fertile_Crescent', 'Fertilizer', 'Fish', 'Flower', 'Food', 'Fossil_fuel', 'France', 'Fruit', 'Germany', 'Global_warming', 'History_of_the_world', 'Honey', 'Horse', 'Indonesia', 'Irrigation', 'Maize', 'Meat', 'Mesopotamia', 'Middle_Ages', 'Milk', 'Nitrogen', 'Nutrition', 'Pea', 'Phosphorus', 'Potato', 'Rice', 'River', 'Soil', 'Soil_salination', 'Sorghum', 'South_America', 'Soybean', 'Sugar', 'Sumer', 'Sweden', 'Tea', 'Tobacco', 'Vegetable', 'Virgil', 'Weed', 'Wheat']\n",
      "choice: Bird\n",
      "Average path length for Agriculture to Sparrow: No path found\n",
      "Invalid choices: 2, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 106/159 [15:35<10:05, 11.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for Aircraft to Solar_eclipse: 8.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 107/159 [15:36<07:21,  8.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for Batman to Superman: 2.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 108/159 [15:45<07:16,  8.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for Batman to Bill_Clinton: 6.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▊   | 109/159 [15:58<08:16,  9.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for Batman to Coconut_crab: 8.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 110/159 [16:04<06:58,  8.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for Brazil to Vitamin: 4.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 111/159 [16:10<06:24,  8.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for Citrus to Desert: 5.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 112/159 [16:27<08:15, 10.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for Continent to Gorilla: 9.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 113/159 [16:36<07:53, 10.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for David_Beckham to Great_white_shark: 9.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 114/159 [16:55<09:37, 12.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for Dog to Elementary_algebra: 8.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 115/159 [17:03<08:12, 11.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for Flower to George_H._W._Bush: 5.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 116/159 [17:24<10:17, 14.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for Forth to Anne_Frank: 11.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▎  | 117/159 [17:39<10:05, 14.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for Mormon to Ice: 8.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 118/159 [17:50<09:05, 13.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for Solar_System to Babe_Ruth: 5.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▍  | 119/159 [18:03<08:55, 13.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for Ocean to Love: 8.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 120/159 [18:10<07:20, 11.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for Seed to New_York_City: 5.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 121/159 [18:19<06:45, 10.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for Weed to Jesus: 5.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 122/159 [18:34<07:20, 11.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for Scent_of_a_Woman to Firearm: 9.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 123/159 [18:41<06:17, 10.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for Meteorological_history_of_Hurricane_Katrina to Iraq_War: 5.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 124/159 [18:55<06:48, 11.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for Chocolate to Velociraptor: 9.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▊  | 125/159 [19:00<05:30,  9.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for Mario to God: 5.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 126/159 [19:13<05:52, 10.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for Age_of_Enlightenment to Kazakhstan: 7.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 127/159 [19:20<04:59,  9.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for American_Civil_War to Kuwait_City: 5.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 128/159 [19:27<04:33,  8.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for Anaconda to Agnosticism: 5.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 129/159 [19:40<04:57,  9.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for Archbishop_of_Canterbury to Neil_Armstrong: 7.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 130/159 [19:42<03:46,  7.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for California to Middle_East: 3.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 131/159 [19:50<03:38,  7.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for Canada to Pony: 6.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 132/159 [19:59<03:36,  8.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for Chemistry to George_H._W._Bush: 5.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▎ | 133/159 [20:16<04:41, 10.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for Colombia to 6th_century: 9.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 134/159 [20:23<04:02,  9.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for Dodo to Film: 5.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 135/159 [20:40<04:43, 11.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for Dog to Beer: 7.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 136/159 [20:41<03:19,  8.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for Germany to Adolf_Hitler: 2.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 137/159 [20:45<02:41,  7.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neighbors: ['Africa', 'Alcohol', 'Ammonia', 'Andes', 'Arable_land', 'Barley', 'Beekeeping', 'Biodiesel', 'Botany', 'Cereal', 'Cocoa', 'Coffee', 'Cotton', 'Egg_(food)', 'Egypt', 'Ethanol', 'Fertile_Crescent', 'Fertilizer', 'Fish', 'Flower', 'Food', 'Fossil_fuel', 'France', 'Fruit', 'Germany', 'History_of_the_world', 'Honey', 'Horse', 'Indonesia', 'Irrigation', 'Maize', 'Meat', 'Mesopotamia', 'Middle_Ages', 'Milk', 'Nitrogen', 'Nutrition', 'Pea', 'Phosphorus', 'Potato', 'Rice', 'River', 'Soil', 'Soil_salination', 'Sorghum', 'South_America', 'Soybean', 'Sugar', 'Sumer', 'Sweden', 'Tea', 'Tobacco', 'Vegetable', 'Virgil', 'Weed', 'Wheat']\n",
      "choice: Wood\n",
      "neighbors: ['Africa', 'Alcohol', 'Ammonia', 'Andes', 'Arable_land', 'Barley', 'Beekeeping', 'Biodiesel', 'Botany', 'Cereal', 'Cocoa', 'Coffee', 'Cotton', 'Egg_(food)', 'Egypt', 'Ethanol', 'Fertile_Crescent', 'Fertilizer', 'Fish', 'Flower', 'Food', 'Fossil_fuel', 'France', 'Fruit', 'Germany', 'History_of_the_world', 'Honey', 'Horse', 'Indonesia', 'Irrigation', 'Maize', 'Meat', 'Mesopotamia', 'Middle_Ages', 'Milk', 'Nitrogen', 'Nutrition', 'Pea', 'Phosphorus', 'Potato', 'Rice', 'River', 'Soil', 'Soil_salination', 'Sorghum', 'South_America', 'Soybean', 'Sugar', 'Sumer', 'Sweden', 'Tea', 'Tobacco', 'Vegetable', 'Virgil', 'Weed', 'Wheat']\n",
      "choice: Wood\n",
      "Average path length for Global_warming to Wood: No path found\n",
      "Invalid choices: 2, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 138/159 [20:57<03:00,  8.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for God to Aztec: 7.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 139/159 [21:14<03:40, 11.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for Gregorian_chant to Inductance: 9.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 140/159 [21:22<03:15, 10.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for Hydrogen to Gold: 4.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▊ | 141/159 [21:31<02:55,  9.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for Judaism to Flute: 6.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 142/159 [21:46<03:15, 11.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for Mathematics to Juice: 11.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 143/159 [21:58<03:06, 11.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for Shark to FIFA: 8.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 144/159 [22:19<03:34, 14.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for Booby to Ununhexium: 11.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 145/159 [22:26<02:49, 12.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for Jesus to Microsoft: 7.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 146/159 [22:31<02:12, 10.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for Pluto to Wall_Street: 4.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 147/159 [22:52<02:38, 13.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for Brain to DVD: 10.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 148/159 [22:58<02:00, 10.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for Planet to Nuclear_power: 5.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▎| 149/159 [23:01<01:26,  8.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for James_Bond to Human_rights: 3.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 150/159 [23:06<01:09,  7.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for Pyramid to Adolf_Hitler: 4.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 151/159 [23:13<00:58,  7.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for Tennis to Nuclear_weapon: 5.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 152/159 [23:18<00:46,  6.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for Khudai_Khidmatgar to Whale: 4.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 153/159 [23:28<00:46,  7.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for Earless_seal to Citrus: 6.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 154/159 [23:36<00:38,  7.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for Wasp to United_Arab_Emirates: 5.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 155/159 [23:46<00:33,  8.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for Weasel to Barium: 7.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 156/159 [23:57<00:27,  9.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for Alpaca to Nuclear_fission: 7.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▊| 157/159 [24:02<00:15,  8.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for Australian_Open to George_W._Bush: 4.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 158/159 [24:05<00:06,  6.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for Necktie to Lion: 3.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 159/159 [24:32<00:00,  9.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average path length for Sonic_the_Hedgehog_%28character%29 to Cancer: 11.0\n",
      "Invalid choices: 0, No path found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import builtins\n",
    "\n",
    "ori_dest = pd.read_csv('ori_dest.csv').iloc[:, 0].tolist()\n",
    "ori_dest = [builtins.eval(pair) for pair in ori_dest]\n",
    "save_dir = 'paths_after_tuning'\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "for pair in tqdm(ori_dest):\n",
    "    start_article, target_article = pair\n",
    "    paths = []\n",
    "    for _ in range(2):\n",
    "        path = generate_path(start_article, target_article, G, model)\n",
    "        paths.append(path)\n",
    "    with open(f'{save_dir}/{start_article}_{target_article}.csv', 'w') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows(paths)\n",
    "    # calculate the average path length\n",
    "    path_lengths = [len(path) for path in paths if path[-1] != 'No path found' and path[-1] != 'Invalid choice']\n",
    "    if len(path_lengths) == 0:\n",
    "        avg_path_length = 'No path found'\n",
    "    else:\n",
    "        avg_path_length = np.mean(path_lengths)\n",
    "    print(f'Average path length for {start_article} to {target_article}: {avg_path_length}')\n",
    "    print(f'Invalid choices: {len([path for path in paths if path[-1] == \"Invalid choice\"])}, No path found: {len([path for path in paths if path[-1] == \"No path found\"])}')\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failure rate before tuning: 0.06918238993710692, after tuning: 0.08176100628930817\n",
      "Number of shorter paths after tuning: -2\n",
      "Average path length before tuning: 5.631205673758865, after tuning: 5.666666666666667\n",
      "T-test result: t-statistic: -0.11453704991684587, p-value: 0.9088941667078448\n"
     ]
    }
   ],
   "source": [
    "# show the defference between before and after tuning the prompt\n",
    "\n",
    "# load the paths\n",
    "paths_before = load_ai_paths('paths_before_tuning', ori_dest)\n",
    "paths_after = load_ai_paths('paths_after_tuning', ori_dest)\n",
    "\n",
    "failure_before = 0\n",
    "failure_after = 0\n",
    "shorter_cnt = 0\n",
    "paths_length_before = []\n",
    "paths_length_after = []\n",
    "\n",
    "for pair in ori_dest:\n",
    "    start_article, target_article = pair\n",
    "    paths = paths_before[pair]\n",
    "    path_lengths = [len(path) for path in paths if path is not None]\n",
    "    if len(path_lengths) == 0:\n",
    "        avg_path_length_before = 'No path found'\n",
    "    else:\n",
    "        avg_path_length_before = np.mean(path_lengths)\n",
    "    if avg_path_length_before == 'No path found':\n",
    "        failure_before += 1\n",
    "\n",
    "    paths = paths_after[pair]\n",
    "    path_lengths = [len(path) for path in paths if path is not None]\n",
    "    if len(path_lengths) == 0:\n",
    "        avg_path_length_after = 'No path found'\n",
    "    else:\n",
    "        avg_path_length_after = np.mean(path_lengths)\n",
    "    if avg_path_length_after == 'No path found':\n",
    "        failure_after += 1\n",
    "\n",
    "    if avg_path_length_before == 'No path found' or avg_path_length_after == 'No path found':\n",
    "        continue\n",
    "    \n",
    "    if avg_path_length_before > avg_path_length_after:\n",
    "        shorter_cnt += 1\n",
    "    elif avg_path_length_before < avg_path_length_after:\n",
    "        shorter_cnt -= 1\n",
    "    \n",
    "    paths_length_before.append(avg_path_length_before)\n",
    "    paths_length_after.append(avg_path_length_after)\n",
    "\n",
    "    '''\n",
    "    if avg_path_length_before != avg_path_length_after:\n",
    "        print(f'Average path length for {start_article} to {target_article} before tuning: {avg_path_length_before}, after tuning: {avg_path_length_after}')\n",
    "    '''\n",
    "    \n",
    "print(f'Failure rate before tuning: {failure_before/len(ori_dest)}, after tuning: {failure_after/len(ori_dest)}')\n",
    "print(f'Number of shorter paths after tuning: {shorter_cnt}')\n",
    "\n",
    "# calculate the statistics of the path length\n",
    "paths_length_before = [length for length in paths_length_before if length != 'No path found']\n",
    "paths_length_after = [length for length in paths_length_after if length != 'No path found']\n",
    "print(f'Average path length before tuning: {np.mean(paths_length_before)}, after tuning: {np.mean(paths_length_after)}')\n",
    "\n",
    "# statistic test\n",
    "from scipy import stats\n",
    "t_stat, p_val = stats.ttest_ind(paths_length_before, paths_length_after)\n",
    "print(f'T-test result: t-statistic: {t_stat}, p-value: {p_val}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
